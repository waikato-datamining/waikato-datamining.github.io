<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data mining (Posts about docker)</title><link>https://www.data-mining.co.nz/</link><description></description><atom:link href="https://www.data-mining.co.nz/categories/cat_docker.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2023 &lt;a href="mailto:fracpete@waikato.ac.nz"&gt;University of Waikato&lt;/a&gt; </copyright><lastBuildDate>Thu, 20 Apr 2023 03:51:24 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Segment-Anything Model Docker images available</title><link>https://www.data-mining.co.nz/news/2023-04-20-sam-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://ai.facebook.com/research/publications/segment-anything/"&gt;Segment-Anything Model&lt;/a&gt; (SAM) are now available.&lt;/p&gt;
&lt;p&gt;SAM is a great tool for aiding a human annotating images for image segmentation or object detection, as it can determine
a relatively good outline of an object based on either a point or a box. Only pre-trained models are available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/segment-anything"&gt;github.com/waikato-datamining/pytorch/tree/master/segment-anything&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam:2023-04-16_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam:2023-04-16_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-04-20-sam-docker/</guid><pubDate>Thu, 20 Apr 2023 01:35:00 GMT</pubDate></item><item><title>DEXTR Docker images available</title><link>https://www.data-mining.co.nz/news/2023-02-24-dextr-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://github.com/Britefury/dextr"&gt;DEXTR&lt;/a&gt; (Deep Extreme Cut) are now available.&lt;/p&gt;
&lt;p&gt;DEXTR is a great tool for aiding a human annotating images for image segmentation, as it can determine
a relatively good outline of an object based on just four extreme points. Pre-trained models are available,
but custom ones (for specific domains) can be trained as well.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/dextr"&gt;github.com/waikato-datamining/pytorch/tree/master/dextr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-dextr:0.1.2_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-dextr:0.1.2_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-02-24-dextr-docker/</guid><pubDate>Fri, 24 Feb 2023 01:35:00 GMT</pubDate></item><item><title>OPEX support expanded</title><link>https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Historically, our object detection frameworks have been outputting predictions in a
&lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations-roi"&gt;CSV-based format&lt;/a&gt; when
doing predictions that involved file-polling (a format that was originally derived from
&lt;a class="reference external" href="https://learn.microsoft.com/en-us/cognitive-toolkit/"&gt;CNTK&lt;/a&gt;). Recent additions
of frameworks (and all Redis-based predictions), however, are using the
&lt;a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format"&gt;OPEX format&lt;/a&gt;
instead (a JSON-based format). In order to standardize the output of our Docker
images further, the following images now offer outputting the predictions in OPEX format
as well:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;MMDetection 2.27.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Detectron2 0.6&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Yolov7 2022-10-08 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/</guid><pubDate>Wed, 25 Jan 2023 03:45:00 GMT</pubDate></item><item><title>OpenMMLab Docker images</title><link>https://www.data-mining.co.nz/news/2023-01-20-openmmlab-docker-images/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;New year, new docker images! This time, we have refreshed our docker images that
use libaries from the &lt;a class="reference external" href="https://github.com/open-mmlab"&gt;OpenMMLab&lt;/a&gt; group:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;MMClassification 0.25.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MMSegmentation 0.30.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MMDetection 2.27.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All frameworks now offer a script (&lt;cite&gt;mmcls/mmseg/mmdet_onnx&lt;/cite&gt;) to export a PyTorch model to ONNX.&lt;/p&gt;
&lt;p&gt;MMDetection now also allows you to select the CUDA device to train on rather
than just always using the first available GPU.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-01-20-openmmlab-docker-images/</guid><pubDate>Fri, 20 Jan 2023 00:30:00 GMT</pubDate></item><item><title>Yolov5 Docker images available</title><link>https://www.data-mining.co.nz/news/2022-11-25-yolov5-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for the latest &lt;a class="reference external" href="https://github.com/ultralytics/yolov5"&gt;Yolov5&lt;/a&gt; code base are now available.
Apart from using a newer codebase, these images now support instance segmentation as well, not just object detection.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/yolov5"&gt;github.com/waikato-datamining/pytorch/tree/master/yolov5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov5:2022-11-05_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov5:2022-11-05_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov5:2022-11-05_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov5:2022-11-05_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The new tutorial on &lt;em&gt;instance segmentation&lt;/em&gt; is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/instance_segmentation/yolov5/"&gt;www.data-mining.co.nz/applied-deep-learning/instance_segmentation/yolov5/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2022-11-25-yolov5-docker/</guid><pubDate>Thu, 24 Nov 2022 21:19:00 GMT</pubDate></item><item><title>Yolov7 Docker images available</title><link>https://www.data-mining.co.nz/news/2022-11-21-yolov7-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for the &lt;a class="reference external" href="https://github.com/WongKinYiu/yolov7"&gt;Yolov7&lt;/a&gt; code base are now available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/yolov7"&gt;github.com/waikato-datamining/pytorch/tree/master/yolov7&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov7:2022-10-08_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov7:2022-10-08_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov7:2022-10-08_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov7:2022-10-08_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A tutorial is available as well:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/object_detection/yolov7/"&gt;www.data-mining.co.nz/applied-deep-learning/object_detection/yolov7/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2022-11-21-yolov7-docker/</guid><pubDate>Mon, 21 Nov 2022 02:33:00 GMT</pubDate></item><item><title>Yolov5 Docker images available</title><link>https://www.data-mining.co.nz/news/2022-09-30-yolov5-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for the latest &lt;a class="reference external" href="https://github.com/ultralytics/yolov5"&gt;Yolov5&lt;/a&gt; code base are now available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/yolov5"&gt;github.com/waikato-datamining/pytorch/tree/master/yolov5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov5:2022-09-29_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov5:2022-09-29_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov5:2022-09-29_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov5:2022-09-29_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2022-09-30-yolov5-docker/</guid><pubDate>Fri, 30 Sep 2022 00:03:00 GMT</pubDate></item><item><title>Coqui STT 1.4.0 (speech-to-text)</title><link>https://www.data-mining.co.nz/news/2022-09-15-coqui_stt/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;A new Docker image is now available for speech-to-text using &lt;a class="reference external" href="https://github.com/coqui-ai/STT"&gt;Coqui STT&lt;/a&gt;
1.4.0 and TensorFlow 1.15.5 on top of CUDA 11.6:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/tensorflow/blob/master/coqui/stt/1.4.0_cuda11.6"&gt;github.com/waikato-datamining/tensorflow/blob/master/coqui/stt/1.4.0_cuda11.6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Check out the new &lt;em&gt;Applied Deep Learning&lt;/em&gt; tutorial on how to use it:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/speech_to_text/coqui_stt/"&gt;www.data-mining.co.nz/applied-deep-learning/speech_to_text/coqui_stt/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2022-09-15-coqui_stt/</guid><pubDate>Thu, 15 Sep 2022 01:19:00 GMT</pubDate></item><item><title>Keras image segmentation Docker image available</title><link>https://www.data-mining.co.nz/news/2022-09-01-keras-image-segmentation-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;A new Docker image of the &lt;em&gt;Keras image segmentation&lt;/em&gt; frameworks is available, now using TensorFlow 2.4.1 and Keras 2.4.3.&lt;/p&gt;
&lt;p&gt;More information on the Docker image is available from Github:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras"&gt;github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2022-09-01-keras-image-segmentation-docker/</guid><pubDate>Thu, 01 Sep 2022 03:55:00 GMT</pubDate></item><item><title>Coqui STT 1.3.0 (speech-to-text)</title><link>https://www.data-mining.co.nz/news/2022-08-31-coqui_stt/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images are now available for speech-to-text using &lt;a class="reference external" href="https://github.com/coqui-ai/STT"&gt;Coqui STT&lt;/a&gt;,
using TensorFlow 1.15.2:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/tensorflow/blob/master/coqui/stt/1.3.0_cuda11.0"&gt;CUDA 11.0&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/tensorflow/tree/master/coqui/stt/1.15.2_0.10.0a10_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2022-08-31-coqui_stt/</guid><pubDate>Wed, 31 Aug 2022 04:43:00 GMT</pubDate></item></channel></rss>