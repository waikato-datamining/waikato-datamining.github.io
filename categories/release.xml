<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data mining (Posts about release)</title><link>https://www.data-mining.co.nz/</link><description></description><atom:link href="https://www.data-mining.co.nz/categories/release.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2025 &lt;a href="mailto:fracpete@waikato.ac.nz"&gt;Applied Machine Learning Group, University of Waikato&lt;/a&gt; </copyright><lastBuildDate>Fri, 27 Jun 2025 04:48:04 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>spectral-data-converter release</title><link>https://www.data-mining.co.nz/news/2025-06-27-sdc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;The first release of our &lt;a class="reference external" href="https://github.com/waikato-datamining/spectral-data-converter-all"&gt;spectral-data-converter-all&lt;/a&gt; library
is now available: &lt;strong&gt;0.0.1&lt;/strong&gt;. Docker images have been deployed as well.&lt;/p&gt;
&lt;p&gt;This library allows you to define and run processing pipelines on the command-line, e.g., for:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;converting data from one format into another (e.g., OPUS to NIR)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clean the data (e.g., IQR)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the data (e.g., SIMPLS, PLS1, standardize)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;build and apply scikit-learn models&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find examples for various scenarios here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/spectral-data-converter-examples/"&gt;data-mining.co.nz/spectral-data-converter-examples/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-06-27-sdc-release/</guid><pubDate>Thu, 26 Jun 2025 22:23:00 GMT</pubDate></item><item><title>djl-arff release</title><link>https://www.data-mining.co.nz/news/2025-05-02-djl-arff-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;&lt;a class="reference external" href="https://djl.ai/"&gt;Deep Java Library (DJL)&lt;/a&gt; is an open source library to build and deploy deep learning in Java,
developed by Amazon.com. Besides the usual image models, it also offers some basic support for tabular data.
Since its input is limited to CSV files, I decided to add support for &lt;a class="reference external" href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/"&gt;Weka ARFF files&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The result of this effort is the &lt;cite&gt;djl-arff&lt;/cite&gt; library:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/djl-arff/"&gt;https://github.com/waikato-datamining/djl-arff/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-05-02-djl-arff-release/</guid><pubDate>Thu, 01 May 2025 23:23:00 GMT</pubDate></item><item><title>BitNet Docker image available</title><link>https://www.data-mining.co.nz/news/2025-04-30-bitnet-docker/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;First Docker image is available for Microsoft's &lt;a class="reference external" href="https://github.com/microsoft/BitNet"&gt;BitNet&lt;/a&gt; small language
model (SLM):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/bitnet/blob/main/2025-04-30_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below is an example on how to use these images (on Linux or on Windows under WSL2).&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;create a directory for your models and output eg "bitnet"&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;in that directory create the following sub-directories&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;cache&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;triton&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;models&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;logs&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interacting with the language model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;from the "bitnet" directory launch the docker image in interactive mode:&lt;/p&gt;
&lt;pre class="literal-block"&gt;docker run --shm-size 8G --net=host \
    -u $(id -u):$(id -g) -e USER=$USER \
    -v `pwd`:/workspace \
    -v `pwd`/cache:/.cache \
    -v `pwd`/triton:/.triton \
    -it waikatodatamining/bitnet:2025-05-30_cpu&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;as a one-off, download the &lt;em&gt;BitNet-b1.58-2B-4T&lt;/em&gt; model from within the Docker container:&lt;/p&gt;
&lt;pre class="literal-block"&gt;huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf \
    --local-dir /workspace/models/BitNet-b1.58-2B-4T&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;once the model is in place, you can interact with with it:&lt;/p&gt;
&lt;pre class="literal-block"&gt;bitnet_run_inference \
    -m /workspace/models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf \
    -p "You are a helpful assistant" \
    -n 1024 \
    -cnv&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-04-30-bitnet-docker/</guid><pubDate>Wed, 30 Apr 2025 04:59:00 GMT</pubDate></item><item><title>S3000 REST webservice support</title><link>https://www.data-mining.co.nz/news/2025-04-03-s3000-rest-support/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;While our commercial framework for laboratories, &lt;a class="reference external" href="https://www.data-mining.co.nz/s3000/"&gt;S3000&lt;/a&gt;, had support for
making predictions via &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Web_service"&gt;webservices&lt;/a&gt; for a long time,
that was limited to asynchronous ones: a webservice endpoint receives data coming in and, once the
predictions have been generated, the results get forwarded to another webservice.&lt;/p&gt;
&lt;p&gt;With recent changes to the codebase, it is now possible to offer synchronous &lt;a class="reference external" href="https://en.wikipedia.org/wiki/REST"&gt;REST webservices&lt;/a&gt;
as well. In order to reduce latency as much as possible, provenance logging under the hood
has been modified to have a much higher throughput that no longer impacts the speed of the predictions.&lt;/p&gt;
&lt;p&gt;Thanks to the plugin architecture of S3000, customer-specific webservices can be implemented and deployed
with minimal effort.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-04-03-s3000-rest-support/</guid><pubDate>Wed, 02 Apr 2025 21:35:00 GMT</pubDate></item><item><title>image-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2025-04-03-idc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;A new release of our &lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-all"&gt;image-dataset-converter-all&lt;/a&gt; library
is now available: &lt;strong&gt;0.0.11&lt;/strong&gt;. Docker images have been deployed as well.&lt;/p&gt;
&lt;p&gt;The most notably changes since 0.0.7 are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;support for placeholders is now available for readers/writers, which can be used in constructing input/output
files/folders, including predefined ones available (&lt;cite&gt;{CWD}&lt;/cite&gt;, &lt;cite&gt;{HOME}&lt;/cite&gt;, &lt;cite&gt;{TMP}&lt;/cite&gt;), input-based ones
(e.g., &lt;cite&gt;{INPUT_PATH}&lt;/cite&gt;, &lt;cite&gt;{INPUT_NAMEEXT}&lt;/cite&gt;), user-defined ones (supplied to tools, e.g., via the &lt;cite&gt;-p/--placeholders&lt;/cite&gt;
option of the &lt;cite&gt;idc-convert&lt;/cite&gt; tool) and run-time ones (set with the &lt;cite&gt;set-placeholder&lt;/cite&gt; filter)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added the &lt;cite&gt;--resume_from&lt;/cite&gt; option to applicable readers, which allows resuming the pipeline from the
file matching the supplied glob, e.g., &lt;cite&gt;*/012345.jpg&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the new &lt;cite&gt;from-multi&lt;/cite&gt; reader and &lt;cite&gt;to-multi&lt;/cite&gt; writer simplify the combining of datasets (from potentially
different formats) and output in multiple formats respectively&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;writers that can split the incoming stream into subsets had the new &lt;cite&gt;--split_group&lt;/cite&gt; option added, which
allows keeping samples together within subsets using a regular expression, e.g., when dealing with
images that were split into sub-grids or augmented with flipping/rotating&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-04-03-idc-release/</guid><pubDate>Wed, 02 Apr 2025 21:23:00 GMT</pubDate></item><item><title>SpeciesNet 4.0.1 Docker images available</title><link>https://www.data-mining.co.nz/news/2025-03-05-speciesnet-docker/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;First Docker images are available for the &lt;a class="reference external" href="https://github.com/google/cameratrapai"&gt;SpeciesNet&lt;/a&gt;
network that &lt;a class="reference external" href="https://blog.google/outreach-initiatives/entrepreneurs/ai-nature-climate-accelerator-nonprofits-speciesnet/"&gt;Google announced on March 3rd, 2025&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/speciesnet/tree/main/4.0.1_cuda12.1"&gt;CUDA 12.1&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/speciesnet/tree/main/4.0.1_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below is an example on how to use these images (on Linux or on Windows under WSL2).&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;create a directory for your output eg "speciesnet"&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;in that directory create the following sub-directories&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;cache&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;config&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;data&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;output&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Processing data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;copy the images that you want to analyze into the "speciesnet/data" directory&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;from the "speciesnet" directory launch the appropriate docker image in interactive mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CPU:&lt;/p&gt;
&lt;pre class="literal-block"&gt;docker run --rm --gpus=all --shm-size 8G --net=host \
  -u $(id -u):$(id -g) -e USER=$USER \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/.cache \
  -v `pwd`/config:/.config \
  -v `pwd`/cache:/.torch \
  -it waikatodatamining/speciesnet:4.0.1_cpu&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;CUDA:&lt;/p&gt;
&lt;pre class="literal-block"&gt;docker run --rm --gpus=all --shm-size 8G --net=host \
  -u $(id -u):$(id -g) -e USER=$USER \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/.cache \
  -v `pwd`/config:/.config \
  -v `pwd`/cache:/.torch \
  -it waikatodatamining/speciesnet:4.0.1_cuda21.1&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;run the following script to process your images:&lt;/p&gt;
&lt;pre class="literal-block"&gt;speciesnet_run_model \
    --folders "/workspace/data" \
    --predictions_json "/workspace/output/predictions.json"&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Or, if you want to run the individual steps separately:&lt;/p&gt;
&lt;pre class="literal-block"&gt;speciesnet_run_model --detector_only \
    --folders "/workspace/data" \
    --predictions_json "/workspace/output/detections.json"
speciesnet_run_model --classifier_only \
    --folders "/workspace/data" \
    --detections_json "/workspace/output/detections.json" \
    --predictions_json "/workspace/output/classifications.json"
speciesnet_run_model --ensemble_only \
    --folders "/workspace/data" \
    --detections_json "/workspace/output/detections.json" \
    --classifications_json "/workspace/output/classifications.json" \
    --predictions_json "/workspace/output/predictions.json"&lt;/pre&gt;
&lt;p&gt;On your host system, the "speciesnet/output" directory will then contain the generated .json file(s), with
"predictions.json" containing all the relevant information (classification and bbox).&lt;/p&gt;
&lt;p&gt;For more information on the json output format:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/google/cameratrapai/tree/main?tab=readme-ov-file#output-format"&gt;https://github.com/google/cameratrapai/tree/main?tab=readme-ov-file#output-format&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-03-05-speciesnet-docker/</guid><pubDate>Wed, 05 Mar 2025 00:21:00 GMT</pubDate></item><item><title>S3000 Python support</title><link>https://www.data-mining.co.nz/news/2025-03-04-s3000-python-support/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;Our commercial offering for laboratories, &lt;a class="reference external" href="https://www.data-mining.co.nz/s3000/"&gt;S3000&lt;/a&gt;, now has official
support for custom Python models. Being a Java application, S3000 historically relied on Weka for its modeling.
However, with the integration of &lt;a class="reference external" href="https://github.com/ninia/jep"&gt;Jep&lt;/a&gt; (Java Embedded Python) in ADAMS, it is now
possible to use scikit-learn or deep learning libraries for training models and making predictions.&lt;/p&gt;
&lt;p&gt;In order to make this work, ADAMS needs to launch from the context of an activated virtual Python environment
that contains all the required Python libraries and then use the &lt;cite&gt;JepRegressor&lt;/cite&gt; Weka meta-classifier to define
the relevant code for training and making predictions. Due to Java serialization not being applicable to Python objects,
these scripts must implement the relevant serialization/deserialization themselves, e.g., via pickle.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-03-04-s3000-python-support/</guid><pubDate>Tue, 04 Mar 2025 04:07:00 GMT</pubDate></item><item><title>image-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2025-02-26-idc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;A new release of our &lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-all"&gt;image-dataset-converter-all&lt;/a&gt; library
is now available: &lt;strong&gt;0.0.7&lt;/strong&gt;. Docker images have been deployed as well.&lt;/p&gt;
&lt;p&gt;The most notably changes are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;added support for the &lt;a class="reference external" href="https://github.com/wkentaro/labelme"&gt;labelme&lt;/a&gt; tool with the
&lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-labelme"&gt;image-dataset-converter-labelme&lt;/a&gt; library,
specifically for the image classification, object detection and instance segmentation JSON file formats&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added support for &lt;a class="reference external" href="https://github.com/PaddlePaddle"&gt;PaddlePaddle&lt;/a&gt; frameworks
with the &lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-paddle"&gt;image-dataset-converter-paddle&lt;/a&gt; library,
specifically for &lt;a class="reference external" href="https://github.com/PaddlePaddle/PaddleClas"&gt;image classification&lt;/a&gt;,
&lt;a class="reference external" href="https://github.com/PaddlePaddle/PaddleDetection"&gt;object detection/instance segmentation&lt;/a&gt;
and &lt;a class="reference external" href="https://github.com/PaddlePaddle/PaddleSeg"&gt;image segmentation&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-02-26-idc-release/</guid><pubDate>Wed, 26 Feb 2025 07:06:00 GMT</pubDate></item><item><title>PaddleDetection 2.8.0 Docker images available</title><link>https://www.data-mining.co.nz/news/2025-02-24-paddleclas-docker/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;First Docker images are available for the &lt;a class="reference external" href="https://github.com/PaddlePaddle/PaddleDetection"&gt;PaddleDetection&lt;/a&gt;
image classification framework, using the 2.8.0 release of PaddleDetection (code base as of 2024-11-06):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/paddledetection/tree/main/2.8.0_cuda11.8"&gt;CUDA 11.8&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/paddledetection/tree/main/2.8.0_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following tutorials are available:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/object_detection/paddledetection/"&gt;Object detection&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/instance_segmentation/paddledetection/"&gt;Instance segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-02-24-paddleclas-docker/</guid><pubDate>Mon, 24 Feb 2025 04:11:00 GMT</pubDate></item><item><title>PaddleClas 2.6.0 Docker images available</title><link>https://www.data-mining.co.nz/news/2025-02-10-paddleclas-docker/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;First Docker images are available for the &lt;a class="reference external" href="https://github.com/PaddlePaddle/PaddleClas"&gt;PaddleClas&lt;/a&gt;
image classification framework, using the 2.6.0 release of PaddleClas (code base as of 2024-11-06):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/paddleclas/tree/main/2.6.0_cuda11.8"&gt;CUDA 11.8&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/paddleclas/tree/main/2.6.0_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A tutorial is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/image_classification/paddleclas/"&gt;https://www.data-mining.co.nz/applied-deep-learning/image_classification/paddleclas/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-02-10-paddleclas-docker/</guid><pubDate>Mon, 10 Feb 2025 02:30:00 GMT</pubDate></item></channel></rss>