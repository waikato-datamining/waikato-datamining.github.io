<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data mining (Posts about release)</title><link>https://www.data-mining.co.nz/</link><description></description><atom:link href="https://www.data-mining.co.nz/categories/release.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2023 &lt;a href="mailto:fracpete@waikato.ac.nz"&gt;University of Waikato&lt;/a&gt; </copyright><lastBuildDate>Thu, 26 Oct 2023 20:53:50 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>llm-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2023-10-27-ldc-release/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Over the last couple of months, we have been working on a little command-line tool that
allows you to convert LLM datasets from one format into another, appropriately called
&lt;cite&gt;llm-dataset-converter&lt;/cite&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter"&gt;https://github.com/waikato-llm/llm-dataset-converter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With the first release (0.0.1), you can not only load data from and save to in various formats
(csv/tsv, text, json, jsonlines, parquet). The tool lets you define pipelines using the following format:&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;reader [filter [filter ...]] [writer]&lt;/cite&gt;&lt;/p&gt;
&lt;p&gt;Each component in the pipeline comes with its own set of command-line parameters. You can even &lt;em&gt;tee&lt;/em&gt; off
records and process them differently (e.g., writing the same data to different output formats).&lt;/p&gt;
&lt;p&gt;The library also has other tools, for downloading files or datasets from huggingface or combining text files.&lt;/p&gt;
&lt;p&gt;In order to make building such pipeline-oriented tools simpler to develop, we created a base library
that manages the handling of plugins (and, if necessary, their compatibility) called &lt;cite&gt;seppl&lt;/cite&gt;
(&lt;em&gt;Simple Entry Point PipeLines&lt;/em&gt;):&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/seppl"&gt;https://github.com/waikato-datamining/seppl&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thanks to seppl, the llm-dataset-converter library can be easily extended with additional modules, as it uses
a dynamic approach to locating plugins: you only need to define in what modules to look for what superclass
(like &lt;cite&gt;Reader&lt;/cite&gt;, &lt;cite&gt;Filter&lt;/cite&gt;, &lt;cite&gt;Writer&lt;/cite&gt;).&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-10-27-ldc-release/</guid><pubDate>Thu, 26 Oct 2023 20:47:00 GMT</pubDate></item><item><title>MMDetection 3.1.0 Docker images available</title><link>https://www.data-mining.co.nz/news/2023-09-01-mmdetection-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;New Docker images are available for the &lt;a class="reference external" href="https://github.com/open-mmlab/mmdetection"&gt;MMDetection&lt;/a&gt; object detection
framework, using the 3.1.0 release of MMDetection (code base as of 2023-06-30):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmdetection/tree/master/3.1.0_cuda11.3"&gt;CUDA 11.3&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmdetection/tree/master/3.1.0_cpu"&gt;CPU&lt;/a&gt; (inference only)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-09-01-mmdetection-docker/</guid><pubDate>Fri, 01 Sep 2023 04:56:00 GMT</pubDate></item><item><title>Finetune GTP2-XL Docker images available</title><link>https://www.data-mining.co.nz/news/2023-08-28-finetune-gpt2xl-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;The &lt;a class="reference external" href="https://github.com/Xirider/finetune-gpt2xl"&gt;finetune-gpt2xl&lt;/a&gt; repository allows the fine-tuning and using of GPT2-XL and GPT-Neo
models (the repository uses the &lt;a class="reference external" href="https://github.com/huggingface/transformers"&gt;Hugging Face transformers library&lt;/a&gt;)
and is now available via the following &lt;a class="reference external" href="https://github.com/waikato-llm/huggingface_transformers/tree/master/4.7.0_cuda11.1_finetune-gpt2xl_20220924"&gt;docker images&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.7.0_cuda11.1_finetune-gpt2xl_20220924&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-huggingface-transformers:4.7.0_cuda11.1_finetune-gpt2xl_20220924&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-08-28-finetune-gpt2xl-docker/</guid><pubDate>Mon, 28 Aug 2023 03:53:00 GMT</pubDate></item><item><title>Segment-Anything in High Quality Docker images available</title><link>https://www.data-mining.co.nz/news/2023-08-28-sam-hq-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://github.com/SysCV/sam-hq"&gt;Segment-Anything in High Quality&lt;/a&gt; (SAM-HQ) are now available.&lt;/p&gt;
&lt;p&gt;Just like &lt;a class="reference external" href="https://www.data-mining.co.nz/news/2023-04-20-sam-docker/"&gt;SAM&lt;/a&gt;, SAM-HQ is a great tool for aiding a human annotating images for image segmentation or object detection, as it can determine
a relatively good outline of an object based on either a point or a box. Only pre-trained models are available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/segment-anything-hq"&gt;github.com/waikato-datamining/pytorch/tree/master/segment-anything-hq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam-hq:2023-08-17_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam-hq:2023-08-17_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam-hq:2023-08-17_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam-hq:2023-08-17_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-08-28-sam-hq-docker/</guid><pubDate>Mon, 28 Aug 2023 03:16:00 GMT</pubDate></item><item><title>Falcontune Docker images available</title><link>https://www.data-mining.co.nz/news/2023-08-21-falcontune-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;The &lt;a class="reference external" href="https://github.com/rmihaylov/falcontune"&gt;falcontune&lt;/a&gt; library for fine-tuning and using Falcon 7B/40B
models (which is based on the &lt;a class="reference external" href="https://github.com/huggingface/transformers"&gt;Hugging Face transformers library&lt;/a&gt;)
is now available via the following &lt;a class="reference external" href="https://github.com/waikato-datamining/huggingface_transformers/tree/master/4.31.0_cuda11.7_falcontune_20230618"&gt;docker images&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.31.0_cuda11.7_falcontune_20230618&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-huggingface-transformers:4.31.0_cuda11.7_falcontune_20230618&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-08-21-falcontune-docker/</guid><pubDate>Mon, 21 Aug 2023 04:39:00 GMT</pubDate></item><item><title>MMSegmentation 1.1.0 Docker images available</title><link>https://www.data-mining.co.nz/news/2023-07-18-mmsegmentation/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for building (and using) image segmentation models using the PyTorch-based framework
&lt;a class="reference external" href="https://github.com/open-mmlab/mmsegmentation"&gt;MMSegmentation&lt;/a&gt; (version 1.1.0) are now available:&lt;/p&gt;
&lt;p&gt;More information on the Docker images is available from Github:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmsegmentation"&gt;https://github.com/waikato-datamining/mmsegmentation&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-07-18-mmsegmentation/</guid><pubDate>Mon, 17 Jul 2023 22:12:00 GMT</pubDate></item><item><title>Segment-Anything Model Docker images available</title><link>https://www.data-mining.co.nz/news/2023-04-20-sam-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://ai.facebook.com/research/publications/segment-anything/"&gt;Segment-Anything Model&lt;/a&gt; (SAM) are now available.&lt;/p&gt;
&lt;p&gt;SAM is a great tool for aiding a human annotating images for image segmentation or object detection, as it can determine
a relatively good outline of an object based on either a point or a box. Only pre-trained models are available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/segment-anything"&gt;github.com/waikato-datamining/pytorch/tree/master/segment-anything&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam:2023-04-16_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam:2023-04-16_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-04-20-sam-docker/</guid><pubDate>Mon, 01 May 2023 00:16:00 GMT</pubDate></item><item><title>opex4j library released</title><link>https://www.data-mining.co.nz/news/2023-03-01-opex47-library-released/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/"&gt;Recently&lt;/a&gt;, we extended the support
for the &lt;a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format"&gt;OPEX format&lt;/a&gt;
in some of our Docker images. So far, there was only language support available for Python.
With today's release of &lt;a class="reference external" href="https://github.com/waikato-datamining/opex4j"&gt;opex4j&lt;/a&gt;, there is
now a Java library for this exchange format available as well.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-03-01-opex47-library-released/</guid><pubDate>Tue, 28 Feb 2023 23:45:00 GMT</pubDate></item><item><title>DEXTR Docker images available</title><link>https://www.data-mining.co.nz/news/2023-02-24-dextr-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://github.com/Britefury/dextr"&gt;DEXTR&lt;/a&gt; (Deep Extreme Cut) are now available.&lt;/p&gt;
&lt;p&gt;DEXTR is a great tool for aiding a human annotating images for image segmentation, as it can determine
a relatively good outline of an object based on just four extreme points. Pre-trained models are available,
but custom ones (for specific domains) can be trained as well.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/dextr"&gt;github.com/waikato-datamining/pytorch/tree/master/dextr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-dextr:0.1.2_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-dextr:0.1.2_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-02-24-dextr-docker/</guid><pubDate>Fri, 24 Feb 2023 01:35:00 GMT</pubDate></item><item><title>OPEX support expanded</title><link>https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Historically, our object detection frameworks have been outputting predictions in a
&lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations-roi"&gt;CSV-based format&lt;/a&gt; when
doing predictions that involved file-polling (a format that was originally derived from
&lt;a class="reference external" href="https://learn.microsoft.com/en-us/cognitive-toolkit/"&gt;CNTK&lt;/a&gt;). Recent additions
of frameworks (and all Redis-based predictions), however, are using the
&lt;a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format"&gt;OPEX format&lt;/a&gt;
instead (a JSON-based format). In order to standardize the output of our Docker
images further, the following images now offer outputting the predictions in OPEX format
as well:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;MMDetection 2.27.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Detectron2 0.6&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Yolov7 2022-10-08 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/</guid><pubDate>Wed, 25 Jan 2023 03:45:00 GMT</pubDate></item></channel></rss>