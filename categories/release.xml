<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data mining (Posts about release)</title><link>https://www.data-mining.co.nz/</link><description></description><atom:link href="https://www.data-mining.co.nz/categories/release.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2023 &lt;a href="mailto:fracpete@waikato.ac.nz"&gt;University of Waikato&lt;/a&gt; </copyright><lastBuildDate>Mon, 28 Aug 2023 04:00:30 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Finetune GTP2-XL Docker images available</title><link>https://www.data-mining.co.nz/news/2023-08-28-finetune-gpt2xl-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;The &lt;a class="reference external" href="https://github.com/Xirider/finetune-gpt2xl"&gt;finetune-gpt2xl&lt;/a&gt; repository allows the fine-tuning and using of GPT2-XL and GPT-Neo
models (the repository uses the &lt;a class="reference external" href="https://github.com/huggingface/transformers"&gt;Hugging Face transformers library&lt;/a&gt;)
and is now available via the following &lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/huggingface_transformers/4.7.0_cuda11.1_finetune-gpt2xl_20220924"&gt;docker images&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.7.0_cuda11.1_finetune-gpt2xl_20220924&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-huggingface-transformers:4.7.0_cuda11.1_finetune-gpt2xl_20220924&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-08-28-finetune-gpt2xl-docker/</guid><pubDate>Mon, 28 Aug 2023 03:53:00 GMT</pubDate></item><item><title>Segment-Anything in High Quality Docker images available</title><link>https://www.data-mining.co.nz/news/2023-08-28-sam-hq-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://github.com/SysCV/sam-hq"&gt;Segment-Anything in High Quality&lt;/a&gt; (SAM-HQ) are now available.&lt;/p&gt;
&lt;p&gt;Just like &lt;a class="reference external" href="https://www.data-mining.co.nz/news/2023-04-20-sam-docker/"&gt;SAM&lt;/a&gt;, SAM-HQ is a great tool for aiding a human annotating images for image segmentation or object detection, as it can determine
a relatively good outline of an object based on either a point or a box. Only pre-trained models are available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/segment-anything-hq"&gt;github.com/waikato-datamining/pytorch/tree/master/segment-anything-hq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam-hq:2023-08-17_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam-hq:2023-08-17_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam-hq:2023-08-17_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam-hq:2023-08-17_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-08-28-sam-hq-docker/</guid><pubDate>Mon, 28 Aug 2023 03:16:00 GMT</pubDate></item><item><title>Falcontune Docker images available</title><link>https://www.data-mining.co.nz/news/2023-08-21-falcontune-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;The &lt;a class="reference external" href="https://github.com/rmihaylov/falcontune"&gt;falcontune&lt;/a&gt; library for fine-tuning and using Falcon 7B/40B
models (which is based on the &lt;a class="reference external" href="https://github.com/huggingface/transformers"&gt;Hugging Face transformers library&lt;/a&gt;)
is now available via the following &lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/huggingface_transformers/4.31.0_cuda11.7_falcontune_20230618"&gt;docker images&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.31.0_cuda11.7_falcontune_20230618&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-huggingface-transformers:4.31.0_cuda11.7_falcontune_20230618&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-08-21-falcontune-docker/</guid><pubDate>Mon, 21 Aug 2023 04:39:00 GMT</pubDate></item><item><title>MMSegmentation 1.1.0 Docker images available</title><link>https://www.data-mining.co.nz/news/2023-07-18-mmsegmentation/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for building (and using) image segmentation models using the PyTorch-based framework
&lt;a class="reference external" href="https://github.com/open-mmlab/mmsegmentation"&gt;MMSegmentation&lt;/a&gt; (version 1.1.0) are now available:&lt;/p&gt;
&lt;p&gt;More information on the Docker images is available from Github:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmsegmentation"&gt;https://github.com/waikato-datamining/mmsegmentation&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-07-18-mmsegmentation/</guid><pubDate>Mon, 17 Jul 2023 22:12:00 GMT</pubDate></item><item><title>Segment-Anything Model Docker images available</title><link>https://www.data-mining.co.nz/news/2023-04-20-sam-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://ai.facebook.com/research/publications/segment-anything/"&gt;Segment-Anything Model&lt;/a&gt; (SAM) are now available.&lt;/p&gt;
&lt;p&gt;SAM is a great tool for aiding a human annotating images for image segmentation or object detection, as it can determine
a relatively good outline of an object based on either a point or a box. Only pre-trained models are available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/segment-anything"&gt;github.com/waikato-datamining/pytorch/tree/master/segment-anything&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam:2023-04-16_cuda11.6&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-sam:2023-04-16_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-04-20-sam-docker/</guid><pubDate>Mon, 01 May 2023 00:16:00 GMT</pubDate></item><item><title>opex4j library released</title><link>https://www.data-mining.co.nz/news/2023-03-01-opex47-library-released/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/"&gt;Recently&lt;/a&gt;, we extended the support
for the &lt;a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format"&gt;OPEX format&lt;/a&gt;
in some of our Docker images. So far, there was only language support available for Python.
With today's release of &lt;a class="reference external" href="https://github.com/waikato-datamining/opex4j"&gt;opex4j&lt;/a&gt;, there is
now a Java library for this exchange format available as well.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-03-01-opex47-library-released/</guid><pubDate>Tue, 28 Feb 2023 23:45:00 GMT</pubDate></item><item><title>DEXTR Docker images available</title><link>https://www.data-mining.co.nz/news/2023-02-24-dextr-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://github.com/Britefury/dextr"&gt;DEXTR&lt;/a&gt; (Deep Extreme Cut) are now available.&lt;/p&gt;
&lt;p&gt;DEXTR is a great tool for aiding a human annotating images for image segmentation, as it can determine
a relatively good outline of an object based on just four extreme points. Pre-trained models are available,
but custom ones (for specific domains) can be trained as well.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/dextr"&gt;github.com/waikato-datamining/pytorch/tree/master/dextr&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-dextr:0.1.2_cuda11.1&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-dextr:0.1.2_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-02-24-dextr-docker/</guid><pubDate>Fri, 24 Feb 2023 01:35:00 GMT</pubDate></item><item><title>OPEX support expanded</title><link>https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Historically, our object detection frameworks have been outputting predictions in a
&lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations-roi"&gt;CSV-based format&lt;/a&gt; when
doing predictions that involved file-polling (a format that was originally derived from
&lt;a class="reference external" href="https://learn.microsoft.com/en-us/cognitive-toolkit/"&gt;CNTK&lt;/a&gt;). Recent additions
of frameworks (and all Redis-based predictions), however, are using the
&lt;a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format"&gt;OPEX format&lt;/a&gt;
instead (a JSON-based format). In order to standardize the output of our Docker
images further, the following images now offer outputting the predictions in OPEX format
as well:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;MMDetection 2.27.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Detectron2 0.6&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Yolov7 2022-10-08 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-01-25-opex-support-expanded/</guid><pubDate>Wed, 25 Jan 2023 03:45:00 GMT</pubDate></item><item><title>OpenMMLab Docker images</title><link>https://www.data-mining.co.nz/news/2023-01-20-openmmlab-docker-images/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;New year, new docker images! This time, we have refreshed our docker images that
use libaries from the &lt;a class="reference external" href="https://github.com/open-mmlab"&gt;OpenMMLab&lt;/a&gt; group:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;MMClassification 0.25.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MMSegmentation 0.30.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MMDetection 2.27.0 (CPU and CUDA 11.1)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All frameworks now offer a script (&lt;cite&gt;mmcls/mmseg/mmdet_onnx&lt;/cite&gt;) to export a PyTorch model to ONNX.&lt;/p&gt;
&lt;p&gt;MMDetection now also allows you to select the CUDA device to train on rather
than just always using the first available GPU.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2023-01-20-openmmlab-docker-images/</guid><pubDate>Fri, 20 Jan 2023 00:30:00 GMT</pubDate></item><item><title>S3000 fusion support</title><link>https://www.data-mining.co.nz/news/2022-12-16-s3000-fusion-support/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Our commercial offering for environmental laboratories, &lt;a class="reference external" href="https://www.data-mining.co.nz/s3000/"&gt;S3000&lt;/a&gt;, now has official data
fusion support. With this in place, labs can now take advantage of combining data generated from the
same sample using multiple instruments (e.g., &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Near-infrared_spectroscopy"&gt;NIR&lt;/a&gt;
and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/X-ray_fluorescence"&gt;XRF&lt;/a&gt;) to improve accuracy of their models.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2022-12-16-s3000-fusion-support/</guid><pubDate>Thu, 15 Dec 2022 21:30:00 GMT</pubDate></item></channel></rss>