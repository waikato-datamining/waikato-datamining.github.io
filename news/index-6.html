<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Commercial AI at the University of Waikato">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Data mining (old posts, page 6) | Data mining</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://www.data-mining.co.nz/news/index-6.html">
<link rel="prev" href="." type="text/html">
<link rel="next" href="index-5.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><link href="../assets/css/custom.css" rel="stylesheet" type="text/css">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../">

            <span id="blog-title">Data mining</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="." class="nav-link">News</a>
                </li>
<li class="nav-item">
<a href="../expertise/" class="nav-link">Expertise</a>
                </li>
<li class="nav-item">
<a href="../services/" class="nav-link">Services</a>
                </li>
<li class="nav-item">
<a href="../s3000/" class="nav-link">Products</a>
                </li>
<li class="nav-item">
<a href="../resources/" class="nav-link">Resources</a>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Who we are</a>
            <div class="dropdown-menu">
                    <a href="../about/" class="dropdown-item">About us</a>
                    <a href="../team/" class="dropdown-item">Meet the Team</a>
                    <a href="../clients/" class="dropdown-item">Our Clients</a>
                    <a href="../contact/" class="dropdown-item">Contact us</a>
            </div>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-06-18-fast-opex/" class="u-url">fast-opex released</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-06-18-fast-opex/" rel="bookmark">
            <time class="published dt-published" datetime="2024-06-18T16:51:00+12:00" itemprop="datePublished" title="2024-06-18 16:51">2024-06-18 16:51</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>The OPEX (<a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format">Object Predictions EXchange</a>)
format features heavily in our docker images for storing/broadcasting predictions. However, last week I noticed
that it incurs quite a significant speed penalty due to its use of JSON schema under the hood.
Since we want to be as fast as possible at prediction time, I sat down and rewrote the library using very basic
(but fast) checks and released it under the name <strong>fast-opex</strong>. The new library works as a drop-in replacement, i.e.,
you only have to switch from installing <strong>opex</strong> to <strong>fast-opex</strong>.</p>
<p>To further speed things up, the new library can take advantage of the blazingly fast
<a class="reference external" href="https://github.com/ijl/orjson">orjson</a> JSON library. The orjson library only needs to be present in the
environment and it will be used automatically.</p>
<p>If you are interested in a speed comparison, then head over to the following repository:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/opex-comparison">https://github.com/waikato-datamining/opex-comparison</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-05-28-faster-whisper/" class="u-url">Faster Whisper 1.0.2 (speech-to-text)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-05-28-faster-whisper/" rel="bookmark">
            <time class="published dt-published" datetime="2024-05-28T08:29:00+12:00" itemprop="datePublished" title="2024-05-28 08:29">2024-05-28 08:29</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>New Docker images are now available for speech-to-text using <a class="reference external" href="https://github.com/SYSTRAN/faster-whisper">Faster Whisper</a> 1.0.2:</p>
<p><a class="reference external" href="https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cuda12.1">https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cuda12.1</a></p>
<p><a class="reference external" href="https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cpu">https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cpu</a></p>
<p>Faster Whisper is a reimplementation of OpenAI's Whisper library with some <a class="reference external" href="https://github.com/SYSTRAN/faster-whisper#benchmark">dramatic speed ups</a>.</p>
<p>With the release of these images, the Coqui STT images have been retired (just like the <a class="reference external" href="https://github.com/coqui-ai/STT/blob/main/README.rst">Coqui STT project itself</a>).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-05-06-idc-release/" class="u-url">image-dataset-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-05-06-idc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2024-05-06T16:12:00+12:00" itemprop="datePublished" title="2024-05-06 16:12">2024-05-06 16:12</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Based on lessons learned from our <a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations">wai-annotations</a> library,
we simplified and streamlined the design of a data processing library (though limited to just image datasets).
Of course, it makes use of the latest <a class="reference external" href="https://github.com/waikato-datamining/seppl">seppl</a> version, which also
simplified how plugins are being located at runtime and development time.</p>
<p>The new kid on the block is called <strong>image-dataset-converter</strong> and its code is located here:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter">https://github.com/waikato-datamining/image-dataset-converter</a></p>
<p>Whilst it is based on wai-annotations, it already contains additional functionality.</p>
<p>And, of course, we also have resources demonstrating how to use the new library:</p>
<p><a class="reference external" href="https://www.data-mining.co.nz/image-dataset-converter-examples/">https://www.data-mining.co.nz/image-dataset-converter-examples/</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-05-06-ldc-release/" class="u-url">llm-dataset-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-05-06-ldc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2024-05-06T13:36:00+12:00" itemprop="datePublished" title="2024-05-06 13:36">2024-05-06 13:36</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Version 0.2.3 of our <em>llm-dataset-converter</em> library is now available.</p>
<p>Quite a number of changes have happened since the first release last year, like xtuner support,
so check out the full change log here:</p>
<p><a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter/blob/main/CHANGES.rst">https://github.com/waikato-llm/llm-dataset-converter/blob/main/CHANGES.rst</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-04-22-xtuner-docker/" class="u-url">XTuner Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-04-22-xtuner-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2024-04-22T11:27:00+12:00" itemprop="datePublished" title="2024-04-22 11:27">2024-04-22 11:27</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Docker images for <a class="reference external" href="https://github.com/InternLM/xtuner">XTuner</a> 0.1.18 are now available:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-xtuner:0.1.18_cuda11.7</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-xtuner:0.1.18_cuda11.7</span></code></p></li>
</ul>
</li>
</ul>
<p>XTuner 0.1.18 now supports the just released llama-3 models (e.g.,
<a class="reference external" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct">Meta-Llama-3-8B-Instruct</a>).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-03-14-mmpretrain-docker/" class="u-url">MMPretrain 1.2.0 Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-03-14-mmpretrain-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2024-03-14T11:55:00+13:00" itemprop="datePublished" title="2024-03-14 11:55">2024-03-14 11:55</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>First Docker images are available for the <a class="reference external" href="https://github.com/open-mmlab/mmpretrain">MMPretrain</a>
framework, using the 1.2.0 release of MMPretrain (code base as of 2024-01-05):</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-datamining/mmpretrain/tree/master/1.2.0_cuda11.1">CUDA 11.1</a></p></li>
<li><p><a class="reference external" href="https://github.com/waikato-datamining/mmpretrain/tree/master/1.2.0_cpu">CPU</a></p></li>
</ul>
<p><strong>NB:</strong> MMPretrain is the successor of MMClassification, which can be used for image classification.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-02-27-xtuner-docker/" class="u-url">XTuner Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-02-27-xtuner-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2024-02-27T16:40:00+13:00" itemprop="datePublished" title="2024-02-27 16:40">2024-02-27 16:40</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p><a class="reference external" href="https://github.com/InternLM/xtuner">XTuner</a> is an efficient, flexible and full-featured toolkit for fine-tuning
large models (InternLM, Llama, Baichuan, Qwen, ChatGLM) and released under the Apache 2.0 license. The advantage
of this framework is that it is not tied down to a specific LLM architecture, but supports multiple ones out of the box.
With the just released version <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter/releases/tag/v0.2.0">v0.2.0</a>
of our <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter">llm-dataset-converter</a> Python library,
you can read and write the XTuner JSON format (and apply the usual filtering, of course).</p>
<p>Here are the newly added image tags:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-xtuner:2024-02-19_cuda11.7</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-xtuner:2024-02-19_cuda11.7</span></code></p></li>
</ul>
</li>
</ul>
<p>Of course, you can use these Docker images in conjunction with our <a class="reference external" href="2023-11-03-gifr-release/">gifr</a>
Python library for <a class="reference external" href="https://www.gradio.app/">gradio</a> interfaces as well (<cite>gifr-textgen</cite>). Just now we released
version 0.0.4 of the library, which is more flexible in regards to text generation: it can now support send and receive
the conversation history and also parse JSON responses.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-02-15-text-classification-support/" class="u-url">Text classification support</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-02-15-text-classification-support/" rel="bookmark">
            <time class="published dt-published" datetime="2024-02-15T16:46:00+13:00" itemprop="datePublished" title="2024-02-15 16:46">2024-02-15 16:46</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Large language models (LLMs) for chatbots are all the rage at the moment, but there is plenty of scope of simpler
tasks like text classification. Requiring less resources and being a lot faster is nice as well.</p>
<p>We turned the <a class="reference external" href="https://huggingface.co/docs/transformers/v4.36.1/en/tasks/sequence_classification">HuggingFace example</a>
for sequence classification into a docker image to make it easy for building such classification models.</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.36.0_cuda11.7_classification</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-huggingface-transformers:4.36.0_cuda11.7_classification</span></code></p></li>
</ul>
</li>
</ul>
<p>Our <a class="reference external" href="https://github.com/waikato-datamining/gifr">gifr</a>
Python library for <a class="reference external" href="https://www.gradio.app/">gradio</a> received an interface for text
classification (<cite>gifr-textclass</cite>) in version 0.0.3.</p>
<p>The <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter">llm-dataset-converter</a> library
obtained native support for text classification formats with version 0.1.1.</p>
    </div>
    </article>
</div>

        <ul class="pager postindexpager clearfix">
<li class="previous"><a href="." rel="prev">Newer posts</a></li>
            <li class="next"><a href="index-5.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer"><footer id="footer" class="footer-1"><div class="main-footer widgets-dark typo-light">

        <div class="container">
            <div class="row">

                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget subscribe no-box">
                        <h5 class="widget-title">AML Group<span></span>
</h5>
                        <p>The Applied Machine Learning Group offers consulting and products in the commercial machine learning space. Operating out of the <a href="https://waikato.ac.nz/">University of Waikato</a></p>
                    </div>
                </div>

                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget no-box">
                        <h5 class="widget-title">Quick Links<span></span>
</h5>
                        <ul class="thumbnail-widget">
<li>
                                <a href=".">News</a>
                            </li>
                            <li>
                                <a href="../expertise/">Expertise</a>
                            </li>
                            <li>
                                <a href="../services/">Services</a>
                            </li>
                            <li>
                                <a href="../s3000/">Products</a>
                            </li>
                            <li>
                                <a href="../resources/">Resources</a>
                            </li>
                        </ul>
</div>
                </div>


                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget no-box">
                        <h5 class="widget-title">Who we are<span></span>
</h5>
                        <ul class="thumbnail-widget">
<li>
                                <a href="../about/">About us</a>
                            </li>
                            <li>
                                <a href="../team/">Meet the team</a>
                            </li>
                            <li>
                                <a href="../clients/">Our Clients</a>
                            </li>
                        </ul>
</div>
                </div>

                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget no-box">
                        <h5 class="widget-title">Contact us<span></span>
</h5>
                        <ul>
<li>
<a href="https://profiles.waikato.ac.nz/peter.reutemann">Peter Reutemann</a><br>fracpete@waikato.ac.nz<p></p>
                            </li>
<li>
<a href="https://profiles.waikato.ac.nz/dale.fletcher">Dale Fletcher</a><br>dale.fletcher@waikato.ac.nz
                        </li>
</ul>
</div>
                </div>

            </div>
        </div>

        <div class="footer-copyright">
            <div class="container">
                <div class="row">
                    <div class="col-md-12 text-center">
                        <p>© 2025 Applied Machine Learning Group, University of Waikato</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</footer></footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
