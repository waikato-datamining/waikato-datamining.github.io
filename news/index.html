<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Commercial data mining activity at the University of Waikato">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Data mining</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://www.data-mining.co.nz/news/">
<link rel="next" href="index-5.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../">

            <span id="blog-title">Data mining</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item active">
<a href="." class="nav-link">News <span class="sr-only">(active)</span></a>
                </li>
<li class="nav-item">
<a href="../expertise/" class="nav-link">Expertise</a>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Services</a>
            <div class="dropdown-menu">
                    <a href="../what-we-offer/" class="dropdown-item">What we offer</a>
                    <a href="../s3000/" class="dropdown-item">S3000</a>
                    <a href="https://adams-advisor.cms.waikato.ac.nz/" class="dropdown-item">Calibration advice</a>
            </div>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Resources</a>
            <div class="dropdown-menu">
                    <a href="../software/" class="dropdown-item">Software</a>
                    <a href="../docker-for-data-scientists/" class="dropdown-item">Docker for Data Scientists</a>
                    <a href="../docker-images/" class="dropdown-item">Docker images</a>
                    <a href="../applied-deep-learning/" class="dropdown-item">Applied Deep Learning</a>
                    <a href="../image-dataset-converter-examples/" class="dropdown-item">image-dataset-converter examples</a>
                    <a href="https://spectral-datasets.github.io/" class="dropdown-item">Spectral datasets</a>
            </div>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
            <div class="dropdown-menu">
                    <a href="../people/" class="dropdown-item">People</a>
                    <a href="../clients/" class="dropdown-item">Clients</a>
                    <a href="../contact/" class="dropdown-item">Contact</a>
            </div>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-05-28-faster-whisper/" class="u-url">Faster Whisper 1.0.2 (speech-to-text)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-05-28-faster-whisper/" rel="bookmark">
            <time class="published dt-published" datetime="2024-05-28T08:29:00+12:00" itemprop="datePublished" title="2024-05-28 08:29">2024-05-28 08:29</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>New Docker images are now available for speech-to-text using <a class="reference external" href="https://github.com/SYSTRAN/faster-whisper">Faster Whisper</a> 1.0.2:</p>
<p><a class="reference external" href="https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cuda12.1">https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cuda12.1</a></p>
<p><a class="reference external" href="https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cpu">https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cpu</a></p>
<p>Faster Whisper is a reimplementation of OpenAI's Whisper library with some <a class="reference external" href="https://github.com/SYSTRAN/faster-whisper#benchmark">dramatic speed ups</a>.</p>
<p>With the release of these images, the Coqui STT images have been retired (just like the <a class="reference external" href="https://github.com/coqui-ai/STT/blob/main/README.rst">Coqui STT project itself</a>).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-05-06-idc-release/" class="u-url">image-dataset-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-05-06-idc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2024-05-06T16:12:00+12:00" itemprop="datePublished" title="2024-05-06 16:12">2024-05-06 16:12</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Based on lessons learned from our <a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations">wai-annotations</a> library,
we simplified and streamlined the design of a data processing library (though limited to just image datasets).
Of course, it makes use of the latest <a class="reference external" href="https://github.com/waikato-datamining/seppl">seppl</a> version, which also
simplified how plugins are being located at runtime and development time.</p>
<p>The new kid on the block is called <strong>image-dataset-converter</strong> and its code is located here:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter">https://github.com/waikato-datamining/image-dataset-converter</a></p>
<p>Whilst it is based on wai-annotations, it already contains additional functionality.</p>
<p>And, of course, we also have resources demonstrating how to use the new library:</p>
<p><a class="reference external" href="https://www.data-mining.co.nz/image-dataset-converter-examples/">https://www.data-mining.co.nz/image-dataset-converter-examples/</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-05-06-ldc-release/" class="u-url">llm-dataset-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-05-06-ldc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2024-05-06T13:36:00+12:00" itemprop="datePublished" title="2024-05-06 13:36">2024-05-06 13:36</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Version 0.2.3 of our <em>llm-dataset-converter</em> library is now available.</p>
<p>Quite a number of changes have happened since the first release last year, like xtuner support,
so check out the full change log here:</p>
<p><a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter/blob/main/CHANGES.rst">https://github.com/waikato-llm/llm-dataset-converter/blob/main/CHANGES.rst</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-04-22-xtuner-docker/" class="u-url">XTuner Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-04-22-xtuner-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2024-04-22T11:27:00+12:00" itemprop="datePublished" title="2024-04-22 11:27">2024-04-22 11:27</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Docker images for <a class="reference external" href="https://github.com/InternLM/xtuner">XTuner</a> 0.1.18 are now available:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-xtuner:0.1.18_cuda11.7</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-xtuner:0.1.18_cuda11.7</span></code></p></li>
</ul>
</li>
</ul>
<p>XTuner 0.1.18 now supports the just released llama-3 models (e.g.,
<a class="reference external" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct">Meta-Llama-3-8B-Instruct</a>).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-03-14-mmpretrain-docker/" class="u-url">MMPretrain 1.2.0 Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-03-14-mmpretrain-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2024-03-14T11:55:00+13:00" itemprop="datePublished" title="2024-03-14 11:55">2024-03-14 11:55</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>First Docker images are available for the <a class="reference external" href="https://github.com/open-mmlab/mmpretrain">MMPretrain</a>
framework, using the 1.2.0 release of MMPretrain (code base as of 2024-01-05):</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-datamining/mmpretrain/tree/master/1.2.0_cuda11.1">CUDA 11.1</a></p></li>
<li><p><a class="reference external" href="https://github.com/waikato-datamining/mmpretrain/tree/master/1.2.0_cpu">CPU</a></p></li>
</ul>
<p><strong>NB:</strong> MMPretrain is the successor of MMClassification, which can be used for image classification.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-02-27-xtuner-docker/" class="u-url">XTuner Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-02-27-xtuner-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2024-02-27T16:40:00+13:00" itemprop="datePublished" title="2024-02-27 16:40">2024-02-27 16:40</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p><a class="reference external" href="https://github.com/InternLM/xtuner">XTuner</a> is an efficient, flexible and full-featured toolkit for fine-tuning
large models (InternLM, Llama, Baichuan, Qwen, ChatGLM) and released under the Apache 2.0 license. The advantage
of this framework is that it is not tied down to a specific LLM architecture, but supports multiple ones out of the box.
With the just released version <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter/releases/tag/v0.2.0">v0.2.0</a>
of our <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter">llm-dataset-converter</a> Python library,
you can read and write the XTuner JSON format (and apply the usual filtering, of course).</p>
<p>Here are the newly added image tags:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-xtuner:2024-02-19_cuda11.7</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-xtuner:2024-02-19_cuda11.7</span></code></p></li>
</ul>
</li>
</ul>
<p>Of course, you can use these Docker images in conjunction with our <a class="reference external" href="2023-11-03-gifr-release/">gifr</a>
Python library for <a class="reference external" href="https://www.gradio.app/">gradio</a> interfaces as well (<cite>gifr-textgen</cite>). Just now we released
version 0.0.4 of the library, which is more flexible in regards to text generation: it can now support send and receive
the conversation history and also parse JSON responses.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2024-02-15-text-classification-support/" class="u-url">Text classification support</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2024-02-15-text-classification-support/" rel="bookmark">
            <time class="published dt-published" datetime="2024-02-15T16:46:00+13:00" itemprop="datePublished" title="2024-02-15 16:46">2024-02-15 16:46</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Large language models (LLMs) for chatbots are all the rage at the moment, but there is plenty of scope of simpler
tasks like text classification. Requiring less resources and being a lot faster is nice as well.</p>
<p>We turned the <a class="reference external" href="https://huggingface.co/docs/transformers/v4.36.1/en/tasks/sequence_classification">HuggingFace example</a>
for sequence classification into a docker image to make it easy for building such classification models.</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.36.0_cuda11.7_classification</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-huggingface-transformers:4.36.0_cuda11.7_classification</span></code></p></li>
</ul>
</li>
</ul>
<p>Our <a class="reference external" href="https://github.com/waikato-datamining/gifr">gifr</a>
Python library for <a class="reference external" href="https://www.gradio.app/">gradio</a> received an interface for text
classification (<cite>gifr-textclass</cite>) in version 0.0.3.</p>
<p>The <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter">llm-dataset-converter</a> library
obtained native support for text classification formats with version 0.1.1.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-11-10-llama2-docker/" class="u-url">Llama-2 Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-11-10-llama2-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2023-11-10T16:33:00+13:00" itemprop="datePublished" title="2023-11-10 16:33">2023-11-10 16:33</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Llama-2, despite <a class="reference external" href="https://blog.opensource.org/metas-llama-2-license-is-not-open-source/">not actually being open-source as advertised</a>,
is a very powerful large language model (LLM), which can also be fine-tuned with custom data. With
version <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter/releases/tag/v0.0.3">v0.0.3</a>
of our <a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter">llm-dataset-converter</a> Python library,
it is now possible to generate data in <a class="reference external" href="https://jsonlines.org/">jsonlines</a> format that the new
<a class="reference external" href="https://github.com/waikato-llm/huggingface_transformers/tree/master/4.31.0_cuda11.7_llama2">Docker images</a>
for Llama-2 can consume:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.31.0_cuda11.7_llama2</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-huggingface-transformers:4.31.0_cuda11.7_llama2</span></code></p></li>
</ul>
</li>
</ul>
<p>Of course, you can use these Docker images in conjunction with our <a class="reference external" href="2023-11-03-gifr-release/">gifr</a>
Python library for <a class="reference external" href="https://www.gradio.app/">gradio</a> interfaces as well (<cite>gifr-textgen</cite>).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-11-03-gifr-release/" class="u-url">gifr release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-11-03-gifr-release/" rel="bookmark">
            <time class="published dt-published" datetime="2023-11-03T14:00:00+13:00" itemprop="datePublished" title="2023-11-03 14:00">2023-11-03 14:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>A lot of our Docker images allow the user to make predictions in two ways: using simple
file-polling or via a <a class="reference external" href="https://redis.io/">Redis</a> backend. File-polling is great for
testing, but unsuitable for a production system due to wear-and-tear on SSDs.</p>
<p>Initially, I developed a really simple library for sending and receiving data via Redis,
called <em>simple-redis-helper</em>:</p>
<p><a class="reference external" href="https://github.com/fracpete/simple-redis-helper">https://github.com/fracpete/simple-redis-helper</a></p>
<p>With this library you get some command-line tools for broadcasting, listening, etc. Sufficient
for someone who is comfortable with the command-line (or especially when logged in remotely
via terminal), but not so great for your clients.</p>
<p>Now, there is the brilliant <a class="reference external" href="https://www.gradio.app/">gradio</a> library that was specifically
developed for such scenarios: to create easy to use and great looking interfaces for your machine
learning models.</p>
<p>The last couple of days, I have put together a new library that is tailored to our Docker images
called <em>gifr</em>:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/gifr">https://github.com/waikato-datamining/gifr</a></p>
<p>With the first release, the following types of models are supported:</p>
<ul class="simple">
<li><p>image classification</p></li>
<li><p>image segmentation</p></li>
<li><p>object detection/instance segmentation</p></li>
<li><p>text generation</p></li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-10-27-ldc-release/" class="u-url">llm-dataset-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-10-27-ldc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2023-10-27T09:47:00+13:00" itemprop="datePublished" title="2023-10-27 09:47">2023-10-27 09:47</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Over the last couple of months, we have been working on a little command-line tool that
allows you to convert LLM datasets from one format into another, appropriately called
<cite>llm-dataset-converter</cite>:</p>
<p><a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter">https://github.com/waikato-llm/llm-dataset-converter</a></p>
<p>With the first release (0.0.1), you can not only load data from and save to in various formats
(csv/tsv, text, json, jsonlines, parquet). The tool lets you define pipelines using the following format:</p>
<p><cite>reader [filter [filter ...]] [writer]</cite></p>
<p>Each component in the pipeline comes with its own set of command-line parameters. You can even <em>tee</em> off
records and process them differently (e.g., writing the same data to different output formats).</p>
<p>The library also has other tools, for downloading files or datasets from huggingface or combining text files.</p>
<p>In order to make building such pipeline-oriented tools simpler to develop, we created a base library
that manages the handling of plugins (and, if necessary, their compatibility) called <cite>seppl</cite>
(<em>Simple Entry Point PipeLines</em>):</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/seppl">https://github.com/waikato-datamining/seppl</a></p>
<p>Thanks to seppl, the llm-dataset-converter library can be easily extended with additional modules, as it uses
a dynamic approach to locating plugins: you only need to define in what modules to look for what superclass
(like <cite>Reader</cite>, <cite>Filter</cite>, <cite>Writer</cite>).</p>
    </div>
    </article>
</div>

        <ul class="pager postindexpager clearfix">
<li class="next"><a href="index-5.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer">
            Contents © 2024         <a href="mailto:fracpete@waikato.ac.nz">University of Waikato</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
