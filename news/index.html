<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Commercial AI at the University of Waikato">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Data mining</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://www.data-mining.co.nz/news/">
<link rel="next" href="index-7.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><link href="../assets/css/custom.css" rel="stylesheet" type="text/css">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../">

            <span id="blog-title">Data mining</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item active">
<a href="." class="nav-link">News <span class="sr-only">(active)</span></a>
                </li>
<li class="nav-item">
<a href="../expertise/" class="nav-link">Expertise</a>
                </li>
<li class="nav-item">
<a href="../services/" class="nav-link">Services</a>
                </li>
<li class="nav-item">
<a href="../s3000/" class="nav-link">Products</a>
                </li>
<li class="nav-item">
<a href="../resources/" class="nav-link">Resources</a>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Who we are</a>
            <div class="dropdown-menu">
                    <a href="../about/" class="dropdown-item">About us</a>
                    <a href="../team/" class="dropdown-item">Meet the Team</a>
                    <a href="../clients/" class="dropdown-item">Our Clients</a>
                    <a href="../contact/" class="dropdown-item">Contact us</a>
            </div>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-06-27-sdc-release/" class="u-url">spectral-data-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-06-27-sdc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2025-06-27T10:23:00+12:00" itemprop="datePublished" title="2025-06-27 10:23">2025-06-27 10:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>The first release of our <a class="reference external" href="https://github.com/waikato-datamining/spectral-data-converter-all">spectral-data-converter-all</a> library
is now available: <strong>0.0.1</strong>. Docker images have been deployed as well.</p>
<p>This library allows you to define and run processing pipelines on the command-line, e.g., for:</p>
<ul class="simple">
<li><p>converting data from one format into another (e.g., OPUS to NIR)</p></li>
<li><p>clean the data (e.g., IQR)</p></li>
<li><p>transform the data (e.g., SIMPLS, PLS1, standardize)</p></li>
<li><p>build and apply scikit-learn models</p></li>
</ul>
<p>You can find examples for various scenarios here:</p>
<p><a class="reference external" href="https://www.data-mining.co.nz/spectral-data-converter-examples/">data-mining.co.nz/spectral-data-converter-examples/</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-05-02-djl-arff-release/" class="u-url">djl-arff release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-05-02-djl-arff-release/" rel="bookmark">
            <time class="published dt-published" datetime="2025-05-02T11:23:00+12:00" itemprop="datePublished" title="2025-05-02 11:23">2025-05-02 11:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p><a class="reference external" href="https://djl.ai/">Deep Java Library (DJL)</a> is an open source library to build and deploy deep learning in Java,
developed by Amazon.com. Besides the usual image models, it also offers some basic support for tabular data.
Since its input is limited to CSV files, I decided to add support for <a class="reference external" href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/">Weka ARFF files</a>.</p>
<p>The result of this effort is the <cite>djl-arff</cite> library:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/djl-arff/">https://github.com/waikato-datamining/djl-arff/</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-04-30-bitnet-docker/" class="u-url">BitNet Docker image available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-04-30-bitnet-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2025-04-30T16:59:00+12:00" itemprop="datePublished" title="2025-04-30 16:59">2025-04-30 16:59</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>First Docker image is available for Microsoft's <a class="reference external" href="https://github.com/microsoft/BitNet">BitNet</a> small language
model (SLM):</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-llm/bitnet/blob/main/2025-04-30_cpu">CPU</a></p></li>
</ul>
<p>Below is an example on how to use these images (on Linux or on Windows under WSL2).</p>
<p>Prerequisites:</p>
<ul class="simple">
<li><p>create a directory for your models and output eg "bitnet"</p></li>
<li>
<p>in that directory create the following sub-directories</p>
<ul>
<li><p>cache</p></li>
<li><p>triton</p></li>
<li><p>models</p></li>
<li><p>logs</p></li>
</ul>
</li>
</ul>
<p>Interacting with the language model:</p>
<ul>
<li>
<p>from the "bitnet" directory launch the docker image in interactive mode:</p>
<pre class="literal-block">docker run --shm-size 8G --net=host \
    -u $(id -u):$(id -g) -e USER=$USER \
    -v `pwd`:/workspace \
    -v `pwd`/cache:/.cache \
    -v `pwd`/triton:/.triton \
    -it waikatodatamining/bitnet:2025-05-30_cpu</pre>
</li>
<li>
<p>as a one-off, download the <em>BitNet-b1.58-2B-4T</em> model from within the Docker container:</p>
<pre class="literal-block">huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf \
    --local-dir /workspace/models/BitNet-b1.58-2B-4T</pre>
</li>
<li>
<p>once the model is in place, you can interact with with it:</p>
<pre class="literal-block">bitnet_run_inference \
    -m /workspace/models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf \
    -p "You are a helpful assistant" \
    -n 1024 \
    -cnv</pre>
</li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-04-03-s3000-rest-support/" class="u-url">S3000 REST webservice support</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-04-03-s3000-rest-support/" rel="bookmark">
            <time class="published dt-published" datetime="2025-04-03T10:35:00+13:00" itemprop="datePublished" title="2025-04-03 10:35">2025-04-03 10:35</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>While our commercial framework for laboratories, <a class="reference external" href="../s3000/">S3000</a>, had support for
making predictions via <a class="reference external" href="https://en.wikipedia.org/wiki/Web_service">webservices</a> for a long time,
that was limited to asynchronous ones: a webservice endpoint receives data coming in and, once the
predictions have been generated, the results get forwarded to another webservice.</p>
<p>With recent changes to the codebase, it is now possible to offer synchronous <a class="reference external" href="https://en.wikipedia.org/wiki/REST">REST webservices</a>
as well. In order to reduce latency as much as possible, provenance logging under the hood
has been modified to have a much higher throughput that no longer impacts the speed of the predictions.</p>
<p>Thanks to the plugin architecture of S3000, customer-specific webservices can be implemented and deployed
with minimal effort.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-04-03-idc-release/" class="u-url">image-dataset-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-04-03-idc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2025-04-03T10:23:00+13:00" itemprop="datePublished" title="2025-04-03 10:23">2025-04-03 10:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>A new release of our <a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-all">image-dataset-converter-all</a> library
is now available: <strong>0.0.11</strong>. Docker images have been deployed as well.</p>
<p>The most notably changes since 0.0.7 are:</p>
<ul class="simple">
<li><p>support for placeholders is now available for readers/writers, which can be used in constructing input/output
files/folders, including predefined ones available (<cite>{CWD}</cite>, <cite>{HOME}</cite>, <cite>{TMP}</cite>), input-based ones
(e.g., <cite>{INPUT_PATH}</cite>, <cite>{INPUT_NAMEEXT}</cite>), user-defined ones (supplied to tools, e.g., via the <cite>-p/--placeholders</cite>
option of the <cite>idc-convert</cite> tool) and run-time ones (set with the <cite>set-placeholder</cite> filter)</p></li>
<li><p>added the <cite>--resume_from</cite> option to applicable readers, which allows resuming the pipeline from the
file matching the supplied glob, e.g., <cite>*/012345.jpg</cite></p></li>
<li><p>the new <cite>from-multi</cite> reader and <cite>to-multi</cite> writer simplify the combining of datasets (from potentially
different formats) and output in multiple formats respectively</p></li>
<li><p>writers that can split the incoming stream into subsets had the new <cite>--split_group</cite> option added, which
allows keeping samples together within subsets using a regular expression, e.g., when dealing with
images that were split into sub-grids or augmented with flipping/rotating</p></li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-03-05-speciesnet-docker/" class="u-url">SpeciesNet 4.0.1 Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-03-05-speciesnet-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-05T13:21:00+13:00" itemprop="datePublished" title="2025-03-05 13:21">2025-03-05 13:21</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>First Docker images are available for the <a class="reference external" href="https://github.com/google/cameratrapai">SpeciesNet</a>
network that <a class="reference external" href="https://blog.google/outreach-initiatives/entrepreneurs/ai-nature-climate-accelerator-nonprofits-speciesnet/">Google announced on March 3rd, 2025</a>:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-datamining/speciesnet/tree/main/4.0.1_cuda12.1">CUDA 12.1</a></p></li>
<li><p><a class="reference external" href="https://github.com/waikato-datamining/speciesnet/tree/main/4.0.1_cpu">CPU</a></p></li>
</ul>
<p>Below is an example on how to use these images (on Linux or on Windows under WSL2).</p>
<p>Prerequisites:</p>
<ul class="simple">
<li><p>create a directory for your output eg "speciesnet"</p></li>
<li>
<p>in that directory create the following sub-directories</p>
<ul>
<li><p>cache</p></li>
<li><p>config</p></li>
<li><p>data</p></li>
<li><p>output</p></li>
</ul>
</li>
</ul>
<p>Processing data:</p>
<ul>
<li><p>copy the images that you want to analyze into the "speciesnet/data" directory</p></li>
<li>
<p>from the "speciesnet" directory launch the appropriate docker image in interactive mode</p>
<ul>
<li>
<p>CPU:</p>
<pre class="literal-block">docker run --rm --gpus=all --shm-size 8G --net=host \
  -u $(id -u):$(id -g) -e USER=$USER \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/.cache \
  -v `pwd`/config:/.config \
  -v `pwd`/cache:/.torch \
  -it waikatodatamining/speciesnet:4.0.1_cpu</pre>
</li>
<li>
<p>CUDA:</p>
<pre class="literal-block">docker run --rm --gpus=all --shm-size 8G --net=host \
  -u $(id -u):$(id -g) -e USER=$USER \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/.cache \
  -v `pwd`/config:/.config \
  -v `pwd`/cache:/.torch \
  -it waikatodatamining/speciesnet:4.0.1_cuda21.1</pre>
</li>
</ul>
</li>
<li>
<p>run the following script to process your images:</p>
<pre class="literal-block">speciesnet_run_model \
    --folders "/workspace/data" \
    --predictions_json "/workspace/output/predictions.json"</pre>
</li>
</ul>
<p>Or, if you want to run the individual steps separately:</p>
<pre class="literal-block">speciesnet_run_model --detector_only \
    --folders "/workspace/data" \
    --predictions_json "/workspace/output/detections.json"
speciesnet_run_model --classifier_only \
    --folders "/workspace/data" \
    --detections_json "/workspace/output/detections.json" \
    --predictions_json "/workspace/output/classifications.json"
speciesnet_run_model --ensemble_only \
    --folders "/workspace/data" \
    --detections_json "/workspace/output/detections.json" \
    --classifications_json "/workspace/output/classifications.json" \
    --predictions_json "/workspace/output/predictions.json"</pre>
<p>On your host system, the "speciesnet/output" directory will then contain the generated .json file(s), with
"predictions.json" containing all the relevant information (classification and bbox).</p>
<p>For more information on the json output format:</p>
<p><a class="reference external" href="https://github.com/google/cameratrapai/tree/main?tab=readme-ov-file#output-format">https://github.com/google/cameratrapai/tree/main?tab=readme-ov-file#output-format</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-03-04-s3000-python-support/" class="u-url">S3000 Python support</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-03-04-s3000-python-support/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-04T17:07:00+13:00" itemprop="datePublished" title="2025-03-04 17:07">2025-03-04 17:07</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Our commercial offering for laboratories, <a class="reference external" href="../s3000/">S3000</a>, now has official
support for custom Python models. Being a Java application, S3000 historically relied on Weka for its modeling.
However, with the integration of <a class="reference external" href="https://github.com/ninia/jep">Jep</a> (Java Embedded Python) in ADAMS, it is now
possible to use scikit-learn or deep learning libraries for training models and making predictions.</p>
<p>In order to make this work, ADAMS needs to launch from the context of an activated virtual Python environment
that contains all the required Python libraries and then use the <cite>JepRegressor</cite> Weka meta-classifier to define
the relevant code for training and making predictions. Due to Java serialization not being applicable to Python objects,
these scripts must implement the relevant serialization/deserialization themselves, e.g., via pickle.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-02-26-idc-release/" class="u-url">image-dataset-converter release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-02-26-idc-release/" rel="bookmark">
            <time class="published dt-published" datetime="2025-02-26T20:06:00+13:00" itemprop="datePublished" title="2025-02-26 20:06">2025-02-26 20:06</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>A new release of our <a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-all">image-dataset-converter-all</a> library
is now available: <strong>0.0.7</strong>. Docker images have been deployed as well.</p>
<p>The most notably changes are:</p>
<ul class="simple">
<li><p>added support for the <a class="reference external" href="https://github.com/wkentaro/labelme">labelme</a> tool with the
<a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-labelme">image-dataset-converter-labelme</a> library,
specifically for the image classification, object detection and instance segmentation JSON file formats</p></li>
<li><p>added support for <a class="reference external" href="https://github.com/PaddlePaddle">PaddlePaddle</a> frameworks
with the <a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-paddle">image-dataset-converter-paddle</a> library,
specifically for <a class="reference external" href="https://github.com/PaddlePaddle/PaddleClas">image classification</a>,
<a class="reference external" href="https://github.com/PaddlePaddle/PaddleDetection">object detection/instance segmentation</a>
and <a class="reference external" href="https://github.com/PaddlePaddle/PaddleSeg">image segmentation</a>.</p></li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-02-24-paddleclas-docker/" class="u-url">PaddleDetection 2.8.0 Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-02-24-paddleclas-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2025-02-24T17:11:00+13:00" itemprop="datePublished" title="2025-02-24 17:11">2025-02-24 17:11</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>First Docker images are available for the <a class="reference external" href="https://github.com/PaddlePaddle/PaddleDetection">PaddleDetection</a>
image classification framework, using the 2.8.0 release of PaddleDetection (code base as of 2024-11-06):</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-datamining/paddledetection/tree/main/2.8.0_cuda11.8">CUDA 11.8</a></p></li>
<li><p><a class="reference external" href="https://github.com/waikato-datamining/paddledetection/tree/main/2.8.0_cpu">CPU</a></p></li>
</ul>
<p>The following tutorials are available:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/object_detection/paddledetection/">Object detection</a></p></li>
<li><p><a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/instance_segmentation/paddledetection/">Instance segmentation</a></p></li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2025-02-10-paddleclas-docker/" class="u-url">PaddleClas 2.6.0 Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Applied Machine Learning Group, University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2025-02-10-paddleclas-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2025-02-10T15:30:00+13:00" itemprop="datePublished" title="2025-02-10 15:30">2025-02-10 15:30</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>First Docker images are available for the <a class="reference external" href="https://github.com/PaddlePaddle/PaddleClas">PaddleClas</a>
image classification framework, using the 2.6.0 release of PaddleClas (code base as of 2024-11-06):</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-datamining/paddleclas/tree/main/2.6.0_cuda11.8">CUDA 11.8</a></p></li>
<li><p><a class="reference external" href="https://github.com/waikato-datamining/paddleclas/tree/main/2.6.0_cpu">CPU</a></p></li>
</ul>
<p>A tutorial is available from here:</p>
<p><a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/image_classification/paddleclas/">https://www.data-mining.co.nz/applied-deep-learning/image_classification/paddleclas/</a></p>
    </div>
    </article>
</div>

        <ul class="pager postindexpager clearfix">
<li class="next"><a href="index-7.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer"><footer id="footer" class="footer-1"><div class="main-footer widgets-dark typo-light">

        <div class="container">
            <div class="row">

                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget subscribe no-box">
                        <h5 class="widget-title">AML Group<span></span>
</h5>
                        <p>The Applied Machine Learning Group offers consulting and products in the commercial machine learning space. Operating out of the <a href="https://waikato.ac.nz/">University of Waikato</a></p>
                    </div>
                </div>

                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget no-box">
                        <h5 class="widget-title">Quick Links<span></span>
</h5>
                        <ul class="thumbnail-widget">
<li>
                                <a href=".">News</a>
                            </li>
                            <li>
                                <a href="../expertise/">Expertise</a>
                            </li>
                            <li>
                                <a href="../services/">Services</a>
                            </li>
                            <li>
                                <a href="../s3000/">Products</a>
                            </li>
                            <li>
                                <a href="../resources/">Resources</a>
                            </li>
                        </ul>
</div>
                </div>


                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget no-box">
                        <h5 class="widget-title">Who we are<span></span>
</h5>
                        <ul class="thumbnail-widget">
<li>
                                <a href="../about/">About us</a>
                            </li>
                            <li>
                                <a href="../team/">Meet the team</a>
                            </li>
                            <li>
                                <a href="../clients/">Our Clients</a>
                            </li>
                        </ul>
</div>
                </div>

                <div class="col-xs-12 col-sm-6 col-md-3">
                    <div class="widget no-box">
                        <h5 class="widget-title">Contact us<span></span>
</h5>
                        <ul>
<li>
<a href="https://profiles.waikato.ac.nz/peter.reutemann">Peter Reutemann</a><br>fracpete@waikato.ac.nz<p></p>
                            </li>
<li>
<a href="https://profiles.waikato.ac.nz/dale.fletcher">Dale Fletcher</a><br>dale.fletcher@waikato.ac.nz
                        </li>
</ul>
</div>
                </div>

            </div>
        </div>

        <div class="footer-copyright">
            <div class="container">
                <div class="row">
                    <div class="col-md-12 text-center">
                        <p>Â© 2025 Applied Machine Learning Group, University of Waikato</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</footer></footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
