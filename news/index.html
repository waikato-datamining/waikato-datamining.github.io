<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Commercial data mining activity at the University of Waikato">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Data mining</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">
<link rel="canonical" href="https://www.data-mining.co.nz/news/">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://www.data-mining.co.nz/">

            <span id="blog-title">Data mining</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item active">
<a href="." class="nav-link">News <span class="sr-only">(active)</span></a>
                </li>
<li class="nav-item">
<a href="../expertise/" class="nav-link">Expertise</a>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Services</a>
            <div class="dropdown-menu">
                    <a href="../what-we-offer/" class="dropdown-item">What we offer</a>
                    <a href="https://adams-advisor.cms.waikato.ac.nz/" class="dropdown-item">Calibration advice</a>
            </div>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
            <div class="dropdown-menu">
                    <a href="../people/" class="dropdown-item">People</a>
                    <a href="../software/" class="dropdown-item">Software</a>
                    <a href="../clients/" class="dropdown-item">Clients</a>
                    <a href="../contact/" class="dropdown-item">Contact</a>
            </div>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2021-01-11-pytorch-image-classification/" class="u-url">PyTorch image classification available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2021-01-11-pytorch-image-classification/" rel="bookmark">
            <time class="published dt-published" datetime="2021-01-11T16:53:00+13:00" itemprop="datePublished" title="2021-01-11 16:53">2021-01-11 16:53</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Today, a new library for performing image classification has made its debut:</p>
<p><strong>wai.pytorchimageclass</strong></p>
<p>The library is based on the PyTorch example code for <a class="reference external" href="https://github.com/pytorch/examples/tree/master/imagenet">imagenet</a>.
For ResNet-based networks, you can finetune pretrained models on your own data rather than
just using the imagenet dataset. In addition, you can make predictions (single and batch/continuous), output information
on built models, export trained models to <a class="reference external" href="https://pytorch.org/docs/stable/jit.html">TorchScript</a>.</p>
<p>The library is also available via Docker images, one for <a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/image-classification/docker/1.6.0">GPU-based</a> machines and one for <a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/image-classification/docker/1.6.0_cpu">CPU-only ones</a>. However, the latter one should only be used for inference and not training, as it is simply too slow.</p>
<p>More information on the library and the Docker images is available from Github:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/image-classification">github.com/waikato-datamining/pytorch/tree/master/image-classification</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2021-01-05-video-frame-processor/" class="u-url">video-frame-processor library released</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2021-01-05-video-frame-processor/" rel="bookmark">
            <time class="published dt-published" datetime="2021-01-05T14:01:00+13:00" itemprop="datePublished" title="2021-01-05 14:01">2021-01-05 14:01</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>The <strong>video-frame-processor</strong> Python 3 library has been released today:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/video-frame-processor">github.com/waikato-datamining/video-frame-processor</a></p>
<p>While it is easy with opencv to open files and webcams, there is no
point in writing the same code over and over again. This is where
the <em>video-frame-processor</em> library comes in, allowing you to
concentrate on the <em>processing</em> of the frames from the video source.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2020-12-13-simple-file-poller/" class="u-url">simple-file-poller library released</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2020-12-13-simple-file-poller/" rel="bookmark">
            <time class="published dt-published" datetime="2020-12-13T09:43:00+13:00" itemprop="datePublished" title="2020-12-13 09:43">2020-12-13 09:43</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>The <strong>simple-file-poller</strong> Python 3 library has been released this week:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/simple-file-poller">github.com/waikato-datamining/simple-file-poller</a></p>
<p>This library is aimed at Python projects that perform continuous processing
of files, e.g., deep learning models that locate objects in images. These
projects typically pick up files from one directory, make predictions,
write the output in some format to another directory and then either
move the input files to the output directory or simply delete them.</p>
<p>Instead of having to write this code for polling and moving over and over
again, the <strong>simple-file-poller</strong> library allows you to plug in your
file processing code via a function that you supply to a <strong>Poller</strong>
object. Furthermore, you can also supply a function that can check whether
files are valid and can be processed (e.g., image files).</p>
<p>The <strong>Poller</strong> class supports two polling modes: time-based and watchdog-based.
The former waits for a specifie number of seconds between polls (if there
were no files present). This simple approach can be used when the file
processing is not time critical. The latter approach watches the input directory
for files being created and then reacts to that immediately. This approach
allows for very low latency processing, especially useful for processing
pipelines.</p>
<p>Another feature is the ability to write any output to a temporary directory
first, before moving it into the output directory. This avoids race conditions
with other processes that further process the generated output files, as the
files are guaranteed to have been fully written.</p>
<p>The following frameworks make use of the <strong>simple-file-poller</strong> now (and more will follow):</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras">image-segmentation-keras</a></p></li>
<li><p><a class="reference external" href="https://github.com/waikato-datamining/mmdetection">mmdetection</a></p></li>
</ul>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2020-08-25-keras-image-segmentation-docker/" class="u-url">Keras image segmentation Docker image available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2020-08-25-keras-image-segmentation-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2020-08-25T14:35:00+12:00" itemprop="datePublished" title="2020-08-25 14:35">2020-08-25 14:35</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>A new Docker image is available for training <em>Keras image segmentation</em> models using a GPU backend.
The image is based on TensorFlow 1.14 and Divam Gupta's <a class="reference external" href="https://github.com/divamgupta/image-segmentation-keras">code</a>,
plus additional tools for converting indexed PNGs into RGB ones and continuously processing images with a model.</p>
<p>More information on the Docker image is available from Github:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras">github.com/waikato-datamining/tensorflow/tree/master/image-segmentation-keras</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2020-08-14-pytorch-docker/" class="u-url">New Pytorch Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2020-08-14-pytorch-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2020-08-14T11:50:00+12:00" itemprop="datePublished" title="2020-08-14 11:50">2020-08-14 11:50</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>A couple of Docker images using <a class="reference external" href="https://pytorch.org/">Pytorch</a> are now available:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/crnn-audio-classification">Audio classification using CRNNs</a>
(code by <a class="reference external" href="https://github.com/ksanjeevan/crnn-audio-classification">Kiran Sanjeevan</a>)</p></li>
<li><p><a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/deepspeech2">DeepSpeech2</a>
(code by <a class="reference external" href="https://github.com/SeanNaren/deepspeech.pytorch">Sean Naren</a>)</p></li>
</ul>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2020-07-03-deepspeech-docker/" class="u-url">DeepSpeech Docker image available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2020-07-03-deepspeech-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2020-07-03T16:26:00+12:00" itemprop="datePublished" title="2020-07-03 16:26">2020-07-03 16:26</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>A new Docker image is available for training <a class="reference external" href="https://github.com/mozilla/DeepSpeech">DeepSpeech</a> models using a GPU backend.
The image is based on Mozilla's DeepSpeech 0.7.4 one for training models, adding more functionality to it:</p>
<ul class="simple">
<li><p>support for MP3 and OGG files, not just WAV</p></li>
<li><p>automatic alphabet generation from the transcripts</p></li>
<li><p>split sound files into chunks based on detected pauses</p></li>
<li><p>batch process audio files (can be continuous)</p></li>
<li><p>many Python utilities have been sym-linked</p></li>
</ul>
<p>More information on the Docker image is available from Github:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/tensorflow/tree/master/deepspeech">github.com/waikato-datamining/tensorflow/tree/master/deepspeech</a></p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2020-06-02-mmdetection-docker/" class="u-url">MMDetection Docker image available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2020-06-02-mmdetection-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2020-06-02T16:21:00+12:00" itemprop="datePublished" title="2020-06-02 16:21">2020-06-02 16:21</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>New Docker images are available for the <a class="reference external" href="https://github.com/open-mmlab/mmdetection">MMDetection</a> object detection framework, using the 1.2.0 (code base as of 2020-03-01) release of MMDetection:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/mmdetection/tree/master/2020-03-01">github.com/waikato-datamining/mmdetection/tree/master/2020-03-01</a></p>
</div>
    </div>
    </article>
</div>







        <!--End of body content-->

        <footer id="footer">
            Contents © 2021         <a href="mailto:fracpete@waikato.ac.nz">University of Waikato</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script>
</body>
</html>
