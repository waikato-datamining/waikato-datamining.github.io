<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Commercial data mining activity at the University of Waikato">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Data mining</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://www.data-mining.co.nz/news/">
<link rel="next" href="index-4.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../">

            <span id="blog-title">Data mining</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item active">
<a href="." class="nav-link">News <span class="sr-only">(active)</span></a>
                </li>
<li class="nav-item">
<a href="../expertise/" class="nav-link">Expertise</a>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Services</a>
            <div class="dropdown-menu">
                    <a href="../what-we-offer/" class="dropdown-item">What we offer</a>
                    <a href="../s3000/" class="dropdown-item">S3000</a>
                    <a href="https://adams-advisor.cms.waikato.ac.nz/" class="dropdown-item">Calibration advice</a>
            </div>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Resources</a>
            <div class="dropdown-menu">
                    <a href="../software/" class="dropdown-item">Software</a>
                    <a href="../docker-for-data-scientists/" class="dropdown-item">Docker for Data Scientists</a>
                    <a href="../docker-images/" class="dropdown-item">Docker images</a>
                    <a href="../applied-deep-learning/" class="dropdown-item">Applied Deep Learning</a>
            </div>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
            <div class="dropdown-menu">
                    <a href="../people/" class="dropdown-item">People</a>
                    <a href="../clients/" class="dropdown-item">Clients</a>
                    <a href="../contact/" class="dropdown-item">Contact</a>
            </div>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-08-28-sam-hq-docker/" class="u-url">Segment-Anything in High Quality Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-08-28-sam-hq-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2023-08-28T15:16:00+12:00" itemprop="datePublished" title="2023-08-28 15:16">2023-08-28 15:16</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Docker images for <a class="reference external" href="https://github.com/SysCV/sam-hq">Segment-Anything in High Quality</a> (SAM-HQ) are now available.</p>
<p>Just like <a class="reference external" href="2023-04-20-sam-docker/">SAM</a>, SAM-HQ is a great tool for aiding a human annotating images for image segmentation or object detection, as it can determine
a relatively good outline of an object based on either a point or a box. Only pre-trained models are available.</p>
<p>The code used by the docker images is available from here:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/segment-anything-hq">github.com/waikato-datamining/pytorch/tree/master/segment-anything-hq</a></p>
<p>The tags for the images are as follows:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam-hq:2023-08-17_cuda11.6</span></code></p></li>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam-hq:2023-08-17_cpu</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-sam-hq:2023-08-17_cuda11.6</span></code></p></li>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-sam-hq:2023-08-17_cpu</span></code></p></li>
</ul>
</li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-08-21-falcontune-docker/" class="u-url">Falcontune Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-08-21-falcontune-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2023-08-21T16:39:00+12:00" itemprop="datePublished" title="2023-08-21 16:39">2023-08-21 16:39</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>The <a class="reference external" href="https://github.com/rmihaylov/falcontune">falcontune</a> library for fine-tuning and using Falcon 7B/40B
models (which is based on the <a class="reference external" href="https://github.com/huggingface/transformers">Hugging Face transformers library</a>)
is now available via the following <a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/huggingface_transformers/4.31.0_cuda11.7_falcontune_20230618">docker images</a>:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-huggingface-transformers:4.31.0_cuda11.7_falcontune_20230618</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-huggingface-transformers:4.31.0_cuda11.7_falcontune_20230618</span></code></p></li>
</ul>
</li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-08-09-redis_updates/" class="u-url">Redis-related Docker image updates</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-08-09-redis_updates/" rel="bookmark">
            <time class="published dt-published" datetime="2023-08-09T11:41:00+12:00" itemprop="datePublished" title="2023-08-09 11:41">2023-08-09 11:41</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>The <a class="reference external" href="https://github.com/waikato-datamining/redis-docker-harness">redis-docker-harness</a>
Python library, which is used by a lot of our Docker images, has received a number of updates
(at time of writing, the version of the library in use is 0.0.4):</p>
<ul class="simple">
<li><p>ability to specify a password for the Redis server</p></li>
<li><p>specify the timeout parameter for the the Redis client, with larger timeouts resulting in
lower CPU load (the default is now 0.01 instead of 0.001)</p></li>
</ul>
<p>Unfortunately, this required re-releasing the most recent images of the following frameworks:</p>
<ul class="simple">
<li><p>detectron2</p></li>
<li><p>mmdetection</p></li>
<li><p>mmsegmentation</p></li>
<li><p>yolov5</p></li>
<li><p>yolov7</p></li>
<li><p>Segment Anything (SAM)</p></li>
<li><p>DEXTR</p></li>
</ul>
<p>The images kept their version number, you just need to pull them again, or use <cite>--pull ALWAYS</cite>
in conjunction with <cite>docker run</cite>.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-07-18-mmsegmentation/" class="u-url">MMSegmentation 1.1.0 Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-07-18-mmsegmentation/" rel="bookmark">
            <time class="published dt-published" datetime="2023-07-18T10:12:00+12:00" itemprop="datePublished" title="2023-07-18 10:12">2023-07-18 10:12</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Docker images for building (and using) image segmentation models using the PyTorch-based framework
<a class="reference external" href="https://github.com/open-mmlab/mmsegmentation">MMSegmentation</a> (version 1.1.0) are now available:</p>
<p>More information on the Docker images is available from Github:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/mmsegmentation">https://github.com/waikato-datamining/mmsegmentation</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-04-20-sam-docker/" class="u-url">Segment-Anything Model Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-04-20-sam-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2023-05-01T13:16:00+13:00" itemprop="datePublished" title="2023-05-01 13:16">2023-05-01 13:16</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Docker images for <a class="reference external" href="https://ai.facebook.com/research/publications/segment-anything/">Segment-Anything Model</a> (SAM) are now available.</p>
<p>SAM is a great tool for aiding a human annotating images for image segmentation or object detection, as it can determine
a relatively good outline of an object based on either a point or a box. Only pre-trained models are available.</p>
<p>The code used by the docker images is available from here:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/segment-anything">github.com/waikato-datamining/pytorch/tree/master/segment-anything</a></p>
<p>The tags for the images are as follows:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cuda11.6</span></code></p></li>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-sam:2023-04-16_cpu</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-sam:2023-04-16_cuda11.6</span></code></p></li>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-sam:2023-04-16_cpu</span></code></p></li>
</ul>
</li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-03-01-opex47-library-released/" class="u-url">opex4j library released</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-03-01-opex47-library-released/" rel="bookmark">
            <time class="published dt-published" datetime="2023-03-01T12:45:00+13:00" itemprop="datePublished" title="2023-03-01 12:45">2023-03-01 12:45</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p><a class="reference external" href="2023-01-25-opex-support-expanded/">Recently</a>, we extended the support
for the <a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format">OPEX format</a>
in some of our Docker images. So far, there was only language support available for Python.
With today's release of <a class="reference external" href="https://github.com/waikato-datamining/opex4j">opex4j</a>, there is
now a Java library for this exchange format available as well.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-02-24-dextr-docker/" class="u-url">DEXTR Docker images available</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-02-24-dextr-docker/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-24T14:35:00+13:00" itemprop="datePublished" title="2023-02-24 14:35">2023-02-24 14:35</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Docker images for <a class="reference external" href="https://github.com/Britefury/dextr">DEXTR</a> (Deep Extreme Cut) are now available.</p>
<p>DEXTR is a great tool for aiding a human annotating images for image segmentation, as it can determine
a relatively good outline of an object based on just four extreme points. Pre-trained models are available,
but custom ones (for specific domains) can be trained as well.</p>
<p>The code used by the docker images is available from here:</p>
<p><a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/dextr">github.com/waikato-datamining/pytorch/tree/master/dextr</a></p>
<p>The tags for the images are as follows:</p>
<ul class="simple">
<li>
<p>In-house registry:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cuda11.1</span></code></p></li>
<li><p><code class="docutils literal"><span class="pre">public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-dextr:0.1.2_cpu</span></code></p></li>
</ul>
</li>
<li>
<p>Docker hub:</p>
<ul>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-dextr:0.1.2_cuda11.1</span></code></p></li>
<li><p><code class="docutils literal"><span class="pre">waikatodatamining/pytorch-dextr:0.1.2_cpu</span></code></p></li>
</ul>
</li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-01-25-opex-support-expanded/" class="u-url">OPEX support expanded</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-01-25-opex-support-expanded/" rel="bookmark">
            <time class="published dt-published" datetime="2023-01-25T16:45:00+13:00" itemprop="datePublished" title="2023-01-25 16:45">2023-01-25 16:45</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Historically, our object detection frameworks have been outputting predictions in a
<a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations-roi">CSV-based format</a> when
doing predictions that involved file-polling (a format that was originally derived from
<a class="reference external" href="https://learn.microsoft.com/en-us/cognitive-toolkit/">CNTK</a>). Recent additions
of frameworks (and all Redis-based predictions), however, are using the
<a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format">OPEX format</a>
instead (a JSON-based format). In order to standardize the output of our Docker
images further, the following images now offer outputting the predictions in OPEX format
as well:</p>
<ul class="simple">
<li><p>MMDetection 2.27.0 (CPU and CUDA 11.1)</p></li>
<li><p>Detectron2 0.6</p></li>
<li><p>Yolov7 2022-10-08 (CPU and CUDA 11.1)</p></li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2023-01-20-openmmlab-docker-images/" class="u-url">OpenMMLab Docker images</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2023-01-20-openmmlab-docker-images/" rel="bookmark">
            <time class="published dt-published" datetime="2023-01-20T13:30:00+13:00" itemprop="datePublished" title="2023-01-20 13:30">2023-01-20 13:30</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>New year, new docker images! This time, we have refreshed our docker images that
use libaries from the <a class="reference external" href="https://github.com/open-mmlab">OpenMMLab</a> group:</p>
<ul class="simple">
<li><p>MMClassification 0.25.0 (CPU and CUDA 11.1)</p></li>
<li><p>MMSegmentation 0.30.0 (CPU and CUDA 11.1)</p></li>
<li><p>MMDetection 2.27.0 (CPU and CUDA 11.1)</p></li>
</ul>
<p>All frameworks now offer a script (<cite>mmcls/mmseg/mmdet_onnx</cite>) to export a PyTorch model to ONNX.</p>
<p>MMDetection now also allows you to select the CUDA device to train on rather
than just always using the first available GPU.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="2022-12-16-s3000-fusion-support/" class="u-url">S3000 fusion support</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                University of Waikato
            </span></p>
            <p class="dateline">
            <a href="2022-12-16-s3000-fusion-support/" rel="bookmark">
            <time class="published dt-published" datetime="2022-12-16T10:30:00+13:00" itemprop="datePublished" title="2022-12-16 10:30">2022-12-16 10:30</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Our commercial offering for environmental laboratories, <a class="reference external" href="../s3000/">S3000</a>, now has official data
fusion support. With this in place, labs can now take advantage of combining data generated from the
same sample using multiple instruments (e.g., <a class="reference external" href="https://en.wikipedia.org/wiki/Near-infrared_spectroscopy">NIR</a>
and <a class="reference external" href="https://en.wikipedia.org/wiki/X-ray_fluorescence">XRF</a>) to improve accuracy of their models.</p>
    </div>
    </article>
</div>

        <ul class="pager postindexpager clearfix">
<li class="next"><a href="index-4.html" rel="next">Older posts</a></li>
        </ul>
<!--End of body content--><footer id="footer">
            Contents Â© 2023         <a href="mailto:fracpete@waikato.ac.nz">University of Waikato</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
