<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data mining</title><link>https://www.data-mining.co.nz/</link><description>Commercial data mining activity at the University of Waikato</description><atom:link href="https://www.data-mining.co.nz/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2024 &lt;a href="mailto:fracpete@waikato.ac.nz"&gt;University of Waikato&lt;/a&gt; </copyright><lastBuildDate>Sun, 01 Sep 2024 20:43:22 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Yolov10 Docker images available</title><link>https://www.data-mining.co.nz/news/2024-07-16-yolov10-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for the latest &lt;a class="reference external" href="https://github.com/THU-MIG/yolov10"&gt;Yolov10&lt;/a&gt; code base are now available.&lt;/p&gt;
&lt;p&gt;The code used by the docker images is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/pytorch/tree/master/yolov10"&gt;github.com/waikato-datamining/pytorch/tree/master/yolov10&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The tags for the images are as follows:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov10:2024-06-23_cuda11.7&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-yolov5:2022-11-05_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov10:2024-06-23_cuda11.7&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-yolov5:2022-11-05_cpu&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The tutorial on &lt;em&gt;object detection&lt;/em&gt; is available from here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/applied-deep-learning/object_detection/yolov10/"&gt;www.data-mining.co.nz/applied-deep-learning/object_detection/yolov10/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-07-16-yolov10-docker/</guid><pubDate>Tue, 16 Jul 2024 02:51:00 GMT</pubDate></item><item><title>audio-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2024-07-05-adc-release/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Today marks the first public release of our &lt;a class="reference external" href="https://github.com/waikato-llm/audio-dataset-converter"&gt;audio-dataset-converter&lt;/a&gt;
library and it various additional dependent libraries.
Just like &lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter"&gt;image-dataset-converter&lt;/a&gt;,
it has its origins in the &lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations"&gt;wai.annotations&lt;/a&gt; library.&lt;/p&gt;
&lt;p&gt;Of course, there is also a meta-library that combines all the libraries:
&lt;a class="reference external" href="https://github.com/waikato-llm/audio-dataset-converter-all"&gt;audio-dataset-converter-all&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Check out the examples site:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://waikato-llm.github.io/audio-dataset-converter-examples/"&gt;https://waikato-llm.github.io/audio-dataset-converter-examples/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-07-05-adc-release/</guid><pubDate>Fri, 05 Jul 2024 01:07:00 GMT</pubDate></item><item><title>llm-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2024-07-05-ldc-release/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Version 0.2.4 of our &lt;a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter"&gt;llm-dataset-converter&lt;/a&gt; library is now available.&lt;/p&gt;
&lt;p&gt;This release is a only minor release, mainly fixing batch processing and offering default globs for readers.
The support for default globs means that the user only has to supply the directory, i.e., in a bash shell it is no
longer required to double quote the input to avoid bash expansion. Additional libraries had support for default globs
added as well where appropriate.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter-all"&gt;llm-dataset-converter-all&lt;/a&gt; meta-library now stands at version 0.0.2.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-07-05-ldc-release/</guid><pubDate>Fri, 05 Jul 2024 01:02:00 GMT</pubDate></item><item><title>image-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2024-07-02-idc-release/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Out &lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter"&gt;image-dataset-converter&lt;/a&gt; library keeps evolving
and, apart from fixing bugs, we also keep adding useful stuff.&lt;/p&gt;
&lt;p&gt;The version of the &lt;cite&gt;image-dataset-converter-all&lt;/cite&gt; library stands now at &lt;strong&gt;0.0.3&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Since version 0.0.2 the following changes occurred:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;image-dataset-converter (core library):&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;switched to the &lt;cite&gt;fast-opex&lt;/cite&gt; library&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;helper method &lt;cite&gt;from_indexedpng&lt;/cite&gt; was using incorrect label index (off by 1)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;Data.save_image&lt;/cite&gt; method now ensures that source/target files exist before calling &lt;cite&gt;os.path.samefile&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;requiring seppl&amp;gt;=0.2.6 now&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;readers now support default globs, allowing the user to just specify directories as input (and the default glob gets appended)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the &lt;cite&gt;to-yolo-od&lt;/cite&gt; writer now has an option for predefined labels (for enforcing label order)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the &lt;cite&gt;to-yolo-od&lt;/cite&gt; writer now stores the labels/labels_cvs files in the respective output folders rather than using an absolute file name&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the bluechannel/grayscale/indexed-png image segmentation readers/writers can use a value other than 0 now for the background&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;cite&gt;split&lt;/cite&gt; filter has been renamed to &lt;cite&gt;split-records&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;image-dataset-converter-imgaug: added &lt;cite&gt;find-contours&lt;/cite&gt; filter for turning blobs in image segmentation annotations into object detection polygons.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;image-dataset-converter-imgvis:  added &lt;cite&gt;add-center-overlay-od&lt;/cite&gt; overlay filter&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;image-dataset-converter-pdf (new module): adds support for PDF, like extracting images from PDF and compiling PDF from images&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-07-02-idc-release/</guid><pubDate>Mon, 01 Jul 2024 21:56:00 GMT</pubDate></item><item><title>fast-opex released</title><link>https://www.data-mining.co.nz/news/2024-06-18-fast-opex/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;The OPEX (&lt;a class="reference external" href="https://github.com/WaikatoLink2020/objdet-predictions-exchange-format"&gt;Object Predictions EXchange&lt;/a&gt;)
format features heavily in our docker images for storing/broadcasting predictions. However, last week I noticed
that it incurs quite a significant speed penalty due to its use of JSON schema under the hood.
Since we want to be as fast as possible at prediction time, I sat down and rewrote the library using very basic
(but fast) checks and released it under the name &lt;strong&gt;fast-opex&lt;/strong&gt;. The new library works as a drop-in replacement, i.e.,
you only have to switch from installing &lt;strong&gt;opex&lt;/strong&gt; to &lt;strong&gt;fast-opex&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To further speed things up, the new library can take advantage of the blazingly fast
&lt;a class="reference external" href="https://github.com/ijl/orjson"&gt;orjson&lt;/a&gt; JSON library. The orjson library only needs to be present in the
environment and it will be used automatically.&lt;/p&gt;
&lt;p&gt;If you are interested in a speed comparison, then head over to the following repository:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/opex-comparison"&gt;https://github.com/waikato-datamining/opex-comparison&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-06-18-fast-opex/</guid><pubDate>Tue, 18 Jun 2024 04:51:00 GMT</pubDate></item><item><title>Faster Whisper 1.0.2 (speech-to-text)</title><link>https://www.data-mining.co.nz/news/2024-05-28-faster-whisper/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;New Docker images are now available for speech-to-text using &lt;a class="reference external" href="https://github.com/SYSTRAN/faster-whisper"&gt;Faster Whisper&lt;/a&gt; 1.0.2:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cuda12.1"&gt;https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cuda12.1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cpu"&gt;https://github.com/waikato-llm/whisper/tree/main/faster-whisper-1.0.2_cpu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Faster Whisper is a reimplementation of OpenAI's Whisper library with some &lt;a class="reference external" href="https://github.com/SYSTRAN/faster-whisper#benchmark"&gt;dramatic speed ups&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With the release of these images, the Coqui STT images have been retired (just like the &lt;a class="reference external" href="https://github.com/coqui-ai/STT/blob/main/README.rst"&gt;Coqui STT project itself&lt;/a&gt;).&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-05-28-faster-whisper/</guid><pubDate>Mon, 27 May 2024 20:29:00 GMT</pubDate></item><item><title>image-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2024-05-06-idc-release/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Based on lessons learned from our &lt;a class="reference external" href="https://github.com/waikato-ufdl/wai-annotations"&gt;wai-annotations&lt;/a&gt; library,
we simplified and streamlined the design of a data processing library (though limited to just image datasets).
Of course, it makes use of the latest &lt;a class="reference external" href="https://github.com/waikato-datamining/seppl"&gt;seppl&lt;/a&gt; version, which also
simplified how plugins are being located at runtime and development time.&lt;/p&gt;
&lt;p&gt;The new kid on the block is called &lt;strong&gt;image-dataset-converter&lt;/strong&gt; and its code is located here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter"&gt;https://github.com/waikato-datamining/image-dataset-converter&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Whilst it is based on wai-annotations, it already contains additional functionality.&lt;/p&gt;
&lt;p&gt;And, of course, we also have resources demonstrating how to use the new library:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/image-dataset-converter-examples/"&gt;https://www.data-mining.co.nz/image-dataset-converter-examples/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-05-06-idc-release/</guid><pubDate>Mon, 06 May 2024 04:12:00 GMT</pubDate></item><item><title>llm-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2024-05-06-ldc-release/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Version 0.2.3 of our &lt;em&gt;llm-dataset-converter&lt;/em&gt; library is now available.&lt;/p&gt;
&lt;p&gt;Quite a number of changes have happened since the first release last year, like xtuner support,
so check out the full change log here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter/blob/main/CHANGES.rst"&gt;https://github.com/waikato-llm/llm-dataset-converter/blob/main/CHANGES.rst&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-05-06-ldc-release/</guid><pubDate>Mon, 06 May 2024 01:36:00 GMT</pubDate></item><item><title>XTuner Docker images available</title><link>https://www.data-mining.co.nz/news/2024-04-22-xtuner-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;Docker images for &lt;a class="reference external" href="https://github.com/InternLM/xtuner"&gt;XTuner&lt;/a&gt; 0.1.18 are now available:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;In-house registry:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;public.aml-repo.cms.waikato.ac.nz:443/pytorch/pytorch-xtuner:0.1.18_cuda11.7&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Docker hub:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code class="docutils literal"&gt;&lt;span class="pre"&gt;waikatodatamining/pytorch-xtuner:0.1.18_cuda11.7&lt;/span&gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;XTuner 0.1.18 now supports the just released llama-3 models (e.g.,
&lt;a class="reference external" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct"&gt;Meta-Llama-3-8B-Instruct&lt;/a&gt;).&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-04-22-xtuner-docker/</guid><pubDate>Sun, 21 Apr 2024 23:27:00 GMT</pubDate></item><item><title>MMPretrain 1.2.0 Docker images available</title><link>https://www.data-mining.co.nz/news/2024-03-14-mmpretrain-docker/</link><dc:creator>University of Waikato</dc:creator><description>&lt;p&gt;First Docker images are available for the &lt;a class="reference external" href="https://github.com/open-mmlab/mmpretrain"&gt;MMPretrain&lt;/a&gt;
framework, using the 1.2.0 release of MMPretrain (code base as of 2024-01-05):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmpretrain/tree/master/1.2.0_cuda11.1"&gt;CUDA 11.1&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/mmpretrain/tree/master/1.2.0_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;NB:&lt;/strong&gt; MMPretrain is the successor of MMClassification, which can be used for image classification.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2024-03-14-mmpretrain-docker/</guid><pubDate>Wed, 13 Mar 2024 22:55:00 GMT</pubDate></item></channel></rss>