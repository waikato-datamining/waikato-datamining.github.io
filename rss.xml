<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data mining</title><link>https://www.data-mining.co.nz/</link><description>Commercial AI at the University of Waikato</description><atom:link href="https://www.data-mining.co.nz/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2025 &lt;a href="mailto:fracpete@waikato.ac.nz"&gt;Applied Machine Learning Group, University of Waikato&lt;/a&gt; </copyright><lastBuildDate>Fri, 31 Oct 2025 02:46:17 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>spectral-data-converter release</title><link>https://www.data-mining.co.nz/news/2025-07-11-sdc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;A new release of our &lt;a class="reference external" href="https://github.com/waikato-datamining/spectral-data-converter-all"&gt;spectral-data-converter-all&lt;/a&gt; library
is now available: &lt;strong&gt;0.0.2&lt;/strong&gt;. Docker images have been deployed as well.&lt;/p&gt;
&lt;p&gt;This release contains couple of major of changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/spectral-data-converter-examples/directio/"&gt;support for direct I/O&lt;/a&gt;: most readers/writers can operate on file-like objects now as well&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/spectral-data-converter-examples/zip/"&gt;reading from/writing to ZIP files&lt;/a&gt;: &lt;cite&gt;from-zip&lt;/cite&gt;, &lt;cite&gt;to-zip&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-07-11-sdc-release/</guid><pubDate>Thu, 10 Jul 2025 23:23:00 GMT</pubDate></item><item><title>image-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2025-07-11-idc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;A new release of our &lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-all"&gt;image-dataset-converter-all&lt;/a&gt; library
is now available: &lt;strong&gt;0.0.12&lt;/strong&gt;. Docker images have been deployed as well.&lt;/p&gt;
&lt;p&gt;The most notably changes since 0.0.11 are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;dropped numpy&amp;lt;2.0.0 restriction&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added grayscale-to-binary filter&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;fix: sort-pixels, rgb-to-grayscale filters&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the rename filter now supports lower/upper case placeholders of name and extension as well&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;requiring seppl&amp;gt;=0.2.17 now for skippable plugin support and avoiding deprecated use of pkg_resources&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added any-to-rgb filter for turning binary/grayscale images back into RGB ones&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added label-to-metadata filter for transferring labels into meta-data&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added metadata-to-placeholder filter for transferring meta-data into placeholders&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added basic support for images with associated depth information: DepthData, DepthInformation&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added depth-to-grayscale filter for converting depth information to grayscale image&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added depth information readers from-grayscale-dp, from-numpy-dp, from-csv-dp and from-pfm-dp&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added depth information writers to-grayscale-dp, to-numpy-dp, to-csv-dp and to-pfm-dp&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added apply-ext-mask filter to applying external PNG masks to image containers (image and/or annotations)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added apply-label-mask filter for applying image segmentation label masks to their base images&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added label-present-ic and label-present-is that ensure that certain label(s) are present or otherwise discard the image&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;filter label-present was renamed to label-present-od but keeping label-present as alias for the time being&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;fix: imgseg_to_bluechannel, imgseg_to_indexedpng and imgseg_to_grayscale now handle overlapping pixels correctly, no longer adding them up and introducing additional labels&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;discard-by-name filter can use names of files in specified paths now as well&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;fixed the construction of the error messages in the pyfunc reader/filter/writer classes&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-07-11-idc-release/</guid><pubDate>Thu, 10 Jul 2025 22:23:00 GMT</pubDate></item><item><title>llm-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2025-07-11-ldc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;Version &lt;strong&gt;0.2.7&lt;/strong&gt; of our &lt;a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter"&gt;llm_dataset_converter&lt;/a&gt; library has
been release. New release of ldc_doc, ldc_docx, ldc_faster_whisper, ldc_google, ldc_openai, ldc_pdf and ldc_tint
have been made available as well.&lt;/p&gt;
&lt;p&gt;The meta-library that combines all the libraries now stands at version &lt;strong&gt;0.0.6&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/llm-dataset-converter-all"&gt;llm-dataset-converter-all&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A new Docker image is available as well:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://hub.docker.com/r/waikatodatamining/llm-dataset-converter/tags"&gt;https://hub.docker.com/r/waikatodatamining/llm-dataset-converter/tags&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This release is mostly a maintenance release, but still had some useful additions:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;added &lt;cite&gt;set-placeholder&lt;/cite&gt; filter for dynamically setting (temporary) placeholders at runtime&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added &lt;cite&gt;remove-strings&lt;/cite&gt; filter that just removes sub-strings&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added &lt;cite&gt;strip-strings&lt;/cite&gt; filter for stripping whitespaces from start/end of strings&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-07-11-ldc-release/</guid><pubDate>Thu, 10 Jul 2025 21:20:00 GMT</pubDate></item><item><title>audio-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2025-07-10-adc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;A new release of our &lt;a class="reference external" href="https://github.com/waikato-llm/audio-dataset-converter"&gt;audio-dataset-converter&lt;/a&gt;
library and it various additional dependent libraries is out.&lt;/p&gt;
&lt;p&gt;The meta-library that combines all the libraries now stands at version &lt;strong&gt;0.0.3&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/audio-dataset-converter-all"&gt;audio-dataset-converter-all&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A new Docker image is available as well:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://hub.docker.com/r/waikatodatamining/audio-dataset-converter/tags"&gt;https://hub.docker.com/r/waikatodatamining/audio-dataset-converter/tags&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Notable changes:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;improved support for placeholders via the &lt;cite&gt;set-placeholder&lt;/cite&gt; and &lt;cite&gt;metadata-to-placeholder&lt;/cite&gt; filters&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added &lt;cite&gt;from-multi&lt;/cite&gt; and &lt;cite&gt;to-multi&lt;/cite&gt; for combining multiple readers/writers&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added the &lt;cite&gt;--resume_from&lt;/cite&gt; option to readers to allow resuming the processing from a specific file&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added the &lt;cite&gt;--split_group&lt;/cite&gt; option ti writers: a regular expression with a single group used for keeping
items in the same split, e.g., for identifying the base name of a file or the ID&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-07-10-adc-release/</guid><pubDate>Thu, 10 Jul 2025 01:07:00 GMT</pubDate></item><item><title>spectral-data-converter release</title><link>https://www.data-mining.co.nz/news/2025-06-27-sdc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;The first release of our &lt;a class="reference external" href="https://github.com/waikato-datamining/spectral-data-converter-all"&gt;spectral-data-converter-all&lt;/a&gt; library
is now available: &lt;strong&gt;0.0.1&lt;/strong&gt;. Docker images have been deployed as well.&lt;/p&gt;
&lt;p&gt;This library allows you to define and run processing pipelines on the command-line, e.g., for:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;converting data from one format into another (e.g., OPUS to NIR)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;clean the data (e.g., IQR)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;transform the data (e.g., SIMPLS, PLS1, standardize)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;build and apply scikit-learn models&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can find examples for various scenarios here:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://www.data-mining.co.nz/spectral-data-converter-examples/"&gt;data-mining.co.nz/spectral-data-converter-examples/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-06-27-sdc-release/</guid><pubDate>Thu, 26 Jun 2025 22:23:00 GMT</pubDate></item><item><title>djl-arff release</title><link>https://www.data-mining.co.nz/news/2025-05-02-djl-arff-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;&lt;a class="reference external" href="https://djl.ai/"&gt;Deep Java Library (DJL)&lt;/a&gt; is an open source library to build and deploy deep learning in Java,
developed by Amazon.com. Besides the usual image models, it also offers some basic support for tabular data.
Since its input is limited to CSV files, I decided to add support for &lt;a class="reference external" href="https://waikato.github.io/weka-wiki/formats_and_processing/arff/"&gt;Weka ARFF files&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The result of this effort is the &lt;cite&gt;djl-arff&lt;/cite&gt; library:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/djl-arff/"&gt;https://github.com/waikato-datamining/djl-arff/&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-05-02-djl-arff-release/</guid><pubDate>Thu, 01 May 2025 23:23:00 GMT</pubDate></item><item><title>BitNet Docker image available</title><link>https://www.data-mining.co.nz/news/2025-04-30-bitnet-docker/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;First Docker image is available for Microsoft's &lt;a class="reference external" href="https://github.com/microsoft/BitNet"&gt;BitNet&lt;/a&gt; small language
model (SLM):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-llm/bitnet/blob/main/2025-04-30_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below is an example on how to use these images (on Linux or on Windows under WSL2).&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;create a directory for your models and output eg "bitnet"&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;in that directory create the following sub-directories&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;cache&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;triton&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;models&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;logs&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interacting with the language model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;from the "bitnet" directory launch the docker image in interactive mode:&lt;/p&gt;
&lt;pre class="literal-block"&gt;docker run --shm-size 8G --net=host \
    -u $(id -u):$(id -g) -e USER=$USER \
    -v `pwd`:/workspace \
    -v `pwd`/cache:/.cache \
    -v `pwd`/triton:/.triton \
    -it waikatodatamining/bitnet:2025-05-30_cpu&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;as a one-off, download the &lt;em&gt;BitNet-b1.58-2B-4T&lt;/em&gt; model from within the Docker container:&lt;/p&gt;
&lt;pre class="literal-block"&gt;huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf \
    --local-dir /workspace/models/BitNet-b1.58-2B-4T&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;once the model is in place, you can interact with with it:&lt;/p&gt;
&lt;pre class="literal-block"&gt;bitnet_run_inference \
    -m /workspace/models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf \
    -p "You are a helpful assistant" \
    -n 1024 \
    -cnv&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-04-30-bitnet-docker/</guid><pubDate>Wed, 30 Apr 2025 04:59:00 GMT</pubDate></item><item><title>S3000 REST webservice support</title><link>https://www.data-mining.co.nz/news/2025-04-03-s3000-rest-support/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;While our commercial framework for laboratories, &lt;a class="reference external" href="https://www.data-mining.co.nz/s3000/"&gt;S3000&lt;/a&gt;, had support for
making predictions via &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Web_service"&gt;webservices&lt;/a&gt; for a long time,
that was limited to asynchronous ones: a webservice endpoint receives data coming in and, once the
predictions have been generated, the results get forwarded to another webservice.&lt;/p&gt;
&lt;p&gt;With recent changes to the codebase, it is now possible to offer synchronous &lt;a class="reference external" href="https://en.wikipedia.org/wiki/REST"&gt;REST webservices&lt;/a&gt;
as well. In order to reduce latency as much as possible, provenance logging under the hood
has been modified to have a much higher throughput that no longer impacts the speed of the predictions.&lt;/p&gt;
&lt;p&gt;Thanks to the plugin architecture of S3000, customer-specific webservices can be implemented and deployed
with minimal effort.&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-04-03-s3000-rest-support/</guid><pubDate>Wed, 02 Apr 2025 21:35:00 GMT</pubDate></item><item><title>image-dataset-converter release</title><link>https://www.data-mining.co.nz/news/2025-04-03-idc-release/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;A new release of our &lt;a class="reference external" href="https://github.com/waikato-datamining/image-dataset-converter-all"&gt;image-dataset-converter-all&lt;/a&gt; library
is now available: &lt;strong&gt;0.0.11&lt;/strong&gt;. Docker images have been deployed as well.&lt;/p&gt;
&lt;p&gt;The most notably changes since 0.0.7 are:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;support for placeholders is now available for readers/writers, which can be used in constructing input/output
files/folders, including predefined ones available (&lt;cite&gt;{CWD}&lt;/cite&gt;, &lt;cite&gt;{HOME}&lt;/cite&gt;, &lt;cite&gt;{TMP}&lt;/cite&gt;), input-based ones
(e.g., &lt;cite&gt;{INPUT_PATH}&lt;/cite&gt;, &lt;cite&gt;{INPUT_NAMEEXT}&lt;/cite&gt;), user-defined ones (supplied to tools, e.g., via the &lt;cite&gt;-p/--placeholders&lt;/cite&gt;
option of the &lt;cite&gt;idc-convert&lt;/cite&gt; tool) and run-time ones (set with the &lt;cite&gt;set-placeholder&lt;/cite&gt; filter)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;added the &lt;cite&gt;--resume_from&lt;/cite&gt; option to applicable readers, which allows resuming the pipeline from the
file matching the supplied glob, e.g., &lt;cite&gt;*/012345.jpg&lt;/cite&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the new &lt;cite&gt;from-multi&lt;/cite&gt; reader and &lt;cite&gt;to-multi&lt;/cite&gt; writer simplify the combining of datasets (from potentially
different formats) and output in multiple formats respectively&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;writers that can split the incoming stream into subsets had the new &lt;cite&gt;--split_group&lt;/cite&gt; option added, which
allows keeping samples together within subsets using a regular expression, e.g., when dealing with
images that were split into sub-grids or augmented with flipping/rotating&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-04-03-idc-release/</guid><pubDate>Wed, 02 Apr 2025 21:23:00 GMT</pubDate></item><item><title>SpeciesNet 4.0.1 Docker images available</title><link>https://www.data-mining.co.nz/news/2025-03-05-speciesnet-docker/</link><dc:creator>Applied Machine Learning Group, University of Waikato</dc:creator><description>&lt;p&gt;First Docker images are available for the &lt;a class="reference external" href="https://github.com/google/cameratrapai"&gt;SpeciesNet&lt;/a&gt;
network that &lt;a class="reference external" href="https://blog.google/outreach-initiatives/entrepreneurs/ai-nature-climate-accelerator-nonprofits-speciesnet/"&gt;Google announced on March 3rd, 2025&lt;/a&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/speciesnet/tree/main/4.0.1_cuda12.1"&gt;CUDA 12.1&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a class="reference external" href="https://github.com/waikato-datamining/speciesnet/tree/main/4.0.1_cpu"&gt;CPU&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below is an example on how to use these images (on Linux or on Windows under WSL2).&lt;/p&gt;
&lt;p&gt;Prerequisites:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;p&gt;create a directory for your output eg "speciesnet"&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;in that directory create the following sub-directories&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;cache&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;config&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;data&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;output&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Processing data:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;copy the images that you want to analyze into the "speciesnet/data" directory&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;from the "speciesnet" directory launch the appropriate docker image in interactive mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CPU:&lt;/p&gt;
&lt;pre class="literal-block"&gt;docker run --rm --gpus=all --shm-size 8G --net=host \
  -u $(id -u):$(id -g) -e USER=$USER \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/.cache \
  -v `pwd`/config:/.config \
  -v `pwd`/cache:/.torch \
  -it waikatodatamining/speciesnet:4.0.1_cpu&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;CUDA:&lt;/p&gt;
&lt;pre class="literal-block"&gt;docker run --rm --gpus=all --shm-size 8G --net=host \
  -u $(id -u):$(id -g) -e USER=$USER \
  -v `pwd`:/workspace \
  -v `pwd`/cache:/.cache \
  -v `pwd`/config:/.config \
  -v `pwd`/cache:/.torch \
  -it waikatodatamining/speciesnet:4.0.1_cuda21.1&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;run the following script to process your images:&lt;/p&gt;
&lt;pre class="literal-block"&gt;speciesnet_run_model \
    --folders "/workspace/data" \
    --predictions_json "/workspace/output/predictions.json"&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Or, if you want to run the individual steps separately:&lt;/p&gt;
&lt;pre class="literal-block"&gt;speciesnet_run_model --detector_only \
    --folders "/workspace/data" \
    --predictions_json "/workspace/output/detections.json"
speciesnet_run_model --classifier_only \
    --folders "/workspace/data" \
    --detections_json "/workspace/output/detections.json" \
    --predictions_json "/workspace/output/classifications.json"
speciesnet_run_model --ensemble_only \
    --folders "/workspace/data" \
    --detections_json "/workspace/output/detections.json" \
    --classifications_json "/workspace/output/classifications.json" \
    --predictions_json "/workspace/output/predictions.json"&lt;/pre&gt;
&lt;p&gt;On your host system, the "speciesnet/output" directory will then contain the generated .json file(s), with
"predictions.json" containing all the relevant information (classification and bbox).&lt;/p&gt;
&lt;p&gt;For more information on the json output format:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/google/cameratrapai/tree/main?tab=readme-ov-file#output-format"&gt;https://github.com/google/cameratrapai/tree/main?tab=readme-ov-file#output-format&lt;/a&gt;&lt;/p&gt;</description><category>release</category><guid>https://www.data-mining.co.nz/news/2025-03-05-speciesnet-docker/</guid><pubDate>Wed, 05 Mar 2025 00:21:00 GMT</pubDate></item></channel></rss>